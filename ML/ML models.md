# SVM
### –õ–∏–Ω–µ–π–Ω–∞—è  SVM
–ì–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å SVM –∫–∞–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ‚Äî –Ω–∞–π—Ç–∏ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª—è—é—â–µ–π –≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç–∏  
![$w_1x_1+w_2x_2+‚Ä¶+w_nx_n+w_0=0$](https://habrastorage.org/getpro/habr/formulas/440/bf4/453/440bf445316d01f98a578314a16e6064.svg)¬†–≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ¬†![$R^n$](https://habrastorage.org/getpro/habr/formulas/3a4/f52/2b1/3a4f522b143bbf174a2d3805dff7536d.svg), –∫–æ—Ç–æ—Ä–∞—è –±—ã —Ä–∞–∑–¥–µ–ª–∏–ª–∞ –¥–≤–∞ –∫–ª–∞—Å—Å–∞ –Ω–µ–∫–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –æ–±—Ä–∞–∑–æ–º. –û–±—â–∏–π –≤–∏–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è¬†![$F$](https://habrastorage.org/getpro/habr/formulas/a0d/d16/4e4/a0dd164e481befe52ca1b226f287b94e.svg)¬†–æ–±—ä–µ–∫—Ç–∞¬†![$x$](https://habrastorage.org/getpro/habr/formulas/4cc/fd4/32e/4ccfd432ea4f2a64f3a5c8c7378517af.svg)¬†–≤ –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞¬†![$Y$](https://habrastorage.org/getpro/habr/formulas/53a/ea9/f07/53aea9f07ccaf30ffac7cd8719e70972.svg):¬†![$F(x) = sign(w^Tx-b)$](https://habrastorage.org/getpro/habr/formulas/f68/424/abf/f68424abf4aaf9d977999f77eeb3629b.svg). –ë—É–¥–µ–º –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ –º—ã –æ–±–æ–∑–Ω–∞—á–∏–ª–∏¬†![$w = (w_1, w_2, ‚Ä¶, w_n), b=-w_0$](https://habrastorage.org/getpro/habr/formulas/7a9/779/9fa/7a97799fa14451b0d95466eb65cc35df.svg). –ü–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Å–æ–≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∞¬†![$w$](https://habrastorage.org/getpro/habr/formulas/499/78e/f12/49978ef12ee6820ac7fc4607771a3586.svg)¬†–∏¬†![$b$](https://habrastorage.org/getpro/habr/formulas/39d/180/62d/39d18062d6d75592f56b1b38409a5e10.svg)¬†(–æ–±—É—á–µ–Ω–∏—è), –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã, –ø–æ–ø–∞–¥–∞—é—â–∏–µ –ø–æ –æ–¥–Ω—É —Å—Ç–æ—Ä–æ–Ω—É –æ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç–∏, –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –∫–∞–∫ –ø–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å, –∞ –æ–±—ä–µ–∫—Ç—ã, –ø–æ–ø–∞–¥–∞—é—â–∏–µ –ø–æ –¥—Ä—É–≥—É—é —Å—Ç–æ—Ä–æ–Ω—É ‚Äî –≤—Ç–æ—Ä–æ–π –∫–ª–∞—Å—Å.


–î–µ—Ñ–æ–ª—Ç–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É¬†_SVM —Å –∂–µ—Å—Ç–∫–∏–º –∑–∞–∑–æ—Ä–æ–º_¬†(_hard-margin SVM_), –∫–æ–≥–¥–∞ –Ω–∏–∫–∞–∫–æ–º—É –æ–±—ä–µ–∫—Ç—É –Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è –ø–æ–ø–∞–¥–∞—Ç—å –Ω–∞ –ø–æ–ª–æ—Å—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –º–æ–∂–Ω–æ –≤—ã—Ä–∞–∑–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º. –†–µ—à–∞–µ—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Ç–µ–æ—Ä–µ–º—É –ö—É–Ω–∞-–¢–∞–∫–∫–µ—Ä–∞. –ü–æ–ª—É—á–∞–µ–º–∞—è –∑–∞–¥–∞—á–∞ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ –¥–≤–æ–π—Å—Ç–≤–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –ø–æ–∏—Å–∫–∞ —Å–µ–¥–ª–æ–≤–æ–π —Ç–æ—á–∫–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –õ–∞–≥—Ä–∞–Ω–∂–∞.

![$ \left\{ \begin{array}{ll} (w^Tw)/2 \rightarrow min & \textrm{}\\ y(w^Tx-b) \geqslant 1 & \textrm{} \end{array} \right. $](https://habrastorage.org/getpro/habr/formulas/cf8/a48/720/cf8a487200e1dafca82cba771de420ed.svg)

### Non-linear SVM
–ü–æ–∑–≤–æ–ª–∏–º –∞–ª–≥–æ—Ä–∏—Ç–º—É –¥–æ–ø—É—Å–∫–∞—Ç—å –æ—à–∏–±–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –ø–æ—Å—Ç–∞—Ä–∞–µ–º—Å—è, —á—Ç–æ–±—ã –æ—à–∏–±–æ–∫ –±—ã–ª–æ –ø–æ–º–µ–Ω—å—à–µ. –í–≤–µ–¥—ë–º –Ω–∞–±–æ—Ä –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö¬†![$\xi _i > 0$](https://habrastorage.org/getpro/habr/formulas/df8/92a/2dd/df892a2ddd95ef764b9059625f9594ba.svg), —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏—Ö –≤–µ–ª–∏—á–∏–Ω—É –æ—à–∏–±–∫–∏ –Ω–∞ –∫–∞–∂–¥–æ–º –æ–±—ä–µ–∫—Ç–µ¬†![$x_i$](https://habrastorage.org/getpro/habr/formulas/341/585/9a0/3415859a0c4e2dbfd25b06a38e760de3.svg). –í–≤–µ–¥—ë–º –≤ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª —à—Ç—Ä–∞—Ñ –∑–∞ —Å—É–º–º–∞—Ä–Ω—É—é –æ—à–∏–±–∫—É:


![$ \left\{ \begin{array}{ll} (w^Tw)/2 + \alpha\sum\xi _i \rightarrow min & \textrm{}\\ y(w^Tx_i-b) \geqslant 1 -\xi _i & \textrm{}\\ \xi _i\geqslant0& \textrm{} \end{array} \right. $](https://habrastorage.org/getpro/habr/formulas/71a/823/9c4/71a8239c468609b7a59aea01d6c26e8d.svg)

–ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (–∫–æ–≥–¥–∞ M<0). –ù–∞–∑–æ–≤–µ–º —ç—Ç–æ —à—Ç—Ä–∞—Ñ–æ–º (_Penalty_).
–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∫ –≤—ã—Ä–∞–∂–µ–Ω–∏—é —à—Ç—Ä–∞—Ñ–∞ —Å–ª–∞–≥–∞–µ–º–æ–µ¬†![$\alpha(w^Tw)/2$](https://habrastorage.org/getpro/habr/formulas/d64/3fd/4a5/d643fd4a5839b0861f29cbc93ea2d0be.svg)¬†–ø–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é —Ñ—É–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å¬†_SVM —Å –º—è–≥–∫–∏–º –∑–∞–∑–æ—Ä–æ–º_¬†(_soft-margin SVM_) –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞:

![$Q =max(0,1- M_i) + \alpha(w^Tw)/2$](https://habrastorage.org/getpro/habr/formulas/5ee/54f/23b/5ee54f23b5ef34510619d757a75f1a66.svg)
![$Q =max(0,1- yw^Tx) + \alpha(w^Tw)/2$](https://habrastorage.org/getpro/habr/formulas/9ee/a84/312/9eea843122a687869f548015a1067002.svg)
![$Q$](https://habrastorage.org/getpro/habr/formulas/3a5/e67/187/3a5e67187c94ffba1bacdbc00b809d08.svg)¬†‚Äî —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å, –æ–Ω–∞ –∂–µ loss function. –ò–º–µ–Ω–Ω–æ –µ–µ –º—ã –∏ –±—É–¥–µ–º –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä—É–∫–∞–º–∏.

### Kernels

Nonlinear SVM addresses linear limitation by utilizing kernel functions to map the data into a higher-dimensional space where linear separation becomes possible.

The kernel function computes the similarity between data points, allowing SVM to capture complex patterns and nonlinear relationships between features. This enables nonlinear SVM to handle intricate data distributions, such as curved or circular decision boundaries.

![[Pasted image 20240218170343.png]]


Once the dual problem is solved and the optimal Lagrange multipliers are determined, the SVM decision boundary can be expressed in terms of these optimal Lagrange multipliers and the support vectors. The support vectors are the training samples with i > 0, and the decision boundary is given by:

![[Pasted image 20240218170515.png]]

The SVM kernel is a function that transforms low-dimensional input space into higher-dimensional space, or in other words, it turns nonseparable problems into separable problems:

![[Pasted image 20240218170542.png]]


# Guide to Ensembling methods

**A group of predictors is called an ensemble**; thus, this technique is called Ensemble Learning, and an Ensemble Learning algorithm is called an¬†**Ensemble method**

## **Types of ensembling :**

**Basic Ensemble Techniques**

- Max Voting
- Averaging
- Weighted Average

**Advanced Ensemble Techniques**

- Stacking
- Blending
- Bagging
- Boosting
**Algorithms based on Bagging and Boosting**

> - Bagging meta-estimator
> - Random Forest
> - AdaBoost
> - GBM
> - XGB
> - Light GBM
> - CatBoost



## Errors
The error emerging from any model can be broken into three components:

![[Pasted image 20240405154852.png]]

**Bias error**

is useful to quantify how much on an average are the predicted values different from the actual value. A high bias error means we have a under-performing model which keeps on missing important trends.

**Variance**

on the other side quantifies how are the prediction made on same observation different from each other. A high variance model will over-fit on your training population and perform badly on any observation beyond training. Following diagram will give you more clarity (Assume that red spot is the real value and blue dots are predictions) :

![[Pasted image 20240405155230.png]]![[Pasted image 20240405155255.png]]

## Max voting

**Implementation**:
```
model1 = tree.DecisionTreeClassifier()
model2 = KNeighborsClassifier()
model3= LogisticRegression()

model1.fit(x_train,y_train)
model2.fit(x_train,y_train)
model3.fit(x_train,y_train)

pred1=model1.predict(x_test)
pred2=model2.predict(x_test)
pred3=model3.predict(x_test)

final_pred = np.array([])
for i in range(0,len(x_test)):
    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))
```
OR (built-in):
```
from sklearn.ensemble import VotingClassifier
model1 = LogisticRegression(random_state=1)
model2 = tree.DecisionTreeClassifier(random_state=1)
model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')
model.fit(x_train,y_train)
model.score(x_test,y_test)
```
## Majority voting/Hard voting

**Soft Voting**

IF all classifiers are able to estimate class probabilities (i.e. they have a predict_proba() method), then you can tell Scikit-Learn to predict the class with the highest class probability, averaged over all the individual classifiers.

This is called¬†**soft voting**¬†and it often achieves higher performance than hard voting because¬†_it gives more weight to highly confident votes_.

**In soft voting**, we predict the class labels based on the predicted probabilities p for classifier -- this approach is only recommended if the classifiers are¬†**well-calibrated**.

_y^=argmax‚àëj=1mwjpij,_¬†where¬†**wj**¬†is the weight that can be assigned to the¬†**jth**¬†classifier.

Assuming the example in the previous section was a¬†_binary classification_¬†task with class labels i‚àà{0,1}, our ensemble could make the following prediction:

C1(x)‚Üí[0.9,0.1]

C2(x)‚Üí[0.8,0.2]

C3(x)‚Üí[0.4,0.6]

Using uniform weights, we compute the average probabilities:

p(i0‚à£x)=0.9+0.8+0.43=0.7p(i1‚à£x)=0.1+0.2+0.63=0.3

y^=argmax[p(i0‚à£x),p(i1‚à£x)]=0


**Averaging**

Similar to the max voting technique, multiple predictions are made for each data point in averaging. In this method, we take an¬†**average**¬†of predictions from all the models and use it to make the final prediction. Averaging can be used for making predictions in regression problems or while calculating probabilities for classification problems. For example, in the below case, the averaging method would take the average of all the values.

```
model1 = tree.DecisionTreeClassifier()
model2 = KNeighborsClassifier()
model3= LogisticRegression()

model1.fit(x_train,y_train)
model2.fit(x_train,y_train)
model3.fit(x_train,y_train)

pred1=model1.predict_proba(x_test)
pred2=model2.predict_proba(x_test)
pred3=model3.predict_proba(x_test)

finalpred=(pred1+pred2+pred3)/3
```


**Weighted averaging**

```
finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)
```

## Advanced techniques

### Bagging

In order for this to work, your data must have¬†_variance_, otherwise you‚Äôre just adding levels after levels of additional iterations with¬†**little benefit**¬†to your score and a big headache for those maintaining your modeling pipeline in production. Even when it does improve things, you have to ask yourself if its worth all that extra work‚Ä¶

In simple terms,¬†**bagging irons out variance from a data set**¬†. If, after splitting your data into multiple chunks and training them, you find that your predictions are¬†_different_, then your data has¬†_variance_. Bagging can turn a bad thing into a competitive advantage. For more theory behind the magic, check out¬†_Bootstrap Aggregating on Wikipedia._¬†Bagging was invented by¬†_Leo Breiman_¬†at the University of California. He is also one of the grandfathers of Boosting and Random Forests.

**Stability and Accuracy**

By saving each prediction set and averaging them together, you not only lower variance without affecting bias, but your accuracy may be¬†**improved**! In essence, you are creating many slightly different models and ensembling them together;¬†**this avoids over-fitting**,¬†**stabilizes your predictions and increases your accuracy**. Mind you, this assumes your data has variance, if it doesn‚Äôt,**bagging won‚Äôt help.**

**Bagging algorithms:**

- Bagging meta-estimator
- Random forest

**Bagging meta-estimator**¬†is an ensembling algorithm that can be used for¬†**both**¬†classification (BaggingClassifier) and regression (BaggingRegressor) problems. It follows the typical bagging technique to make predictions. Following are the steps for the bagging meta-estimator algorithm:

1-Random subsets are created from the original dataset (Bootstrapping).

2-The subset of the dataset includes all features.

3-A user-specified base estimator is fitted on each of these smaller sets.

4-Predictions from each model are combined to get the final result.

```
final_dt = DecisionTreeClassifier(max_leaf_nodes=10, max_depth=5)                   
final_bc = BaggingClassifier(base_estimator=final_dt, n_estimators=40, random_state=1, oob_score=True)

final_bc.fit(X_train, train_y)
final_preds = final_bc.predict(X_test)

acc_oob = final_bc.oob_score_
print(acc_oob)
```

**Random Forest**¬†is another ensemble machine learning algorithm that follows the bagging technique. It is an extension of the bagging estimator algorithm. The base estimators in random forest are decision trees. Unlike bagging meta estimator, random forest¬†**randomly**¬†selects a set of features which are used to decide the best split at each node of the decision tree.

step-by-step, this is what a random forest model does:

1-Random subsets are created from the original dataset (bootstrapping).

2-At each node in the decision tree, only a random set of features are considered to decide the best split.

3-A decision tree model is fitted on each of the subsets. The final prediction is calculated by averaging the predictions from all decision trees.

**Note:**¬†The decision trees in random forest can be built on a subset of data and features. Particularly, the sklearn model of random forest uses all features for decision tree and a subset of features are randomly selected for splitting at each node.
### Boosting

The term ‚ÄòBoosting‚Äô refers to a family of algorithms which¬†**converts weak learner to strong learners**. Boosting is an ensemble method for improving the model predictions of any given learning algorithm. The idea of boosting¬†**is to train weak learners sequentially, each trying to correct its predecessor**.

**Adaptive boosting or AdaBoost**¬†is one of the simplest boosting algorithms. Usually, decision trees are used for modelling. Multiple sequential models are created, each correcting the errors from the last model. AdaBoost assigns weights to the observations which are incorrectly predicted and the subsequent model works to predict these values correctly.

**steps:**

1-all observations in the dataset are given equal weights.

2-A model is built on a subset of data.

3-Using this model, predictions are made on the whole dataset.

4-Errors are calculated by comparing the predictions and actual values.

5-While creating the next model, higher weights are given to the data points which were predicted incorrectly.

6-Weights can be determined using the error value. For instance, higher the error more is the weight assigned to the observation.

7-This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached.



### Stacking

Stacking is a similar to boosting:

you also apply several models to your original data. The difference here is, however, that you don't have just an empirical formula for your weight function, rather you introduce a meta-level and use another model/approach to estimate the input together with outputs of every model to estimate the weights or, in other words, to determine what models perform well and what badly given these input data. and finally I get its true illustration.

#  üç≤ ModelSoups
–ê–≤—Ç–æ—Ä—ã —Å—Ç–∞—Ç—å–∏ ‚Äú[Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time](https://arxiv.org/abs/2203.05482)‚Äù –æ–ø–∏—Å–∞–ª–∏ —Å–≤–æ–π –ø–æ–¥—Ö–æ–¥ –∏ –ø—Ä–æ–≤–µ–ª–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—é –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π. –°–¥–µ–ª–∞–Ω–æ —ç—Ç–æ –±—ã–ª–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –Ω–∞–∏–ª—É—á—à–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏.

**–ò–¥–µ–∞–ª—å–Ω–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è** —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã ‚Äî —Ç–µ—Ö–Ω–∏–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª–∏–ª–∞ –±—ã –ø–æ–ª—É—á–∏—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª—é —Å–≤–æ–π—Å—Ç–≤–∞ –ø—Ä–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, —Ä–∞–≤–Ω—ã–º –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –ï—Å—Ç—å —Å–ø–æ—Å–æ–± —Ä–µ—à–µ–Ω–∏—è –ø–æ–¥–æ–±–Ω–æ–π –∑–∞–¥–∞—á–∏: —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π. –í —Ä–∞–º–∫–∞—Ö —ç—Ç–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –æ–±—â–∏–π –ø–æ–¥—Ö–æ–¥:

1. –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —ç–ø–æ—Ö–∞—Ö.
2. –ü–æ–¥–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç–∞—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–ø—Ä–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–∏ –∏—Ö –≤–µ—Å–æ–≤ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –Ω–∞–∏–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å).
3. –í—ã–±–∏—Ä–∞–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –æ–¥–∏–Ω –∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è.

–ü–æ—Å–ª–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è —É –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —É–ª—É—á—à–∞—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:

1. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
2. –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Å–¥–≤–∏–≥–∞–º –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∏ out-of-distribution –ø—Ä–∏–º–µ—Ä–∞–º.

## –ö–∞–∫ –≤–∞—Ä–∏–º?

### –ó–∞–¥–∞—á–∞

–ù–∞—á–Ω–µ–º —Å –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–¥–∞—á–∏. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–π —á–∞—â–µ –≤—Å–µ–≥–æ –ø—Ä–∏–º–µ–Ω—è—é—Ç –ø—Ä–∏ —Ä–µ—à–µ–Ω–∏–∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∑–∞–¥–∞—á:

1. –ù–∞—Ö–æ–¥–∏–º –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â—É—é –Ω–∞—Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ —á–µ–∫–ø–æ–∏–Ω—Ç, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –≤ —Ä–µ–∂–∏–º–µ supervised –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö / –≤ self-supervised —Ä–µ–∂–∏–º–µ.
2. –ú–µ–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª–æ–π, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫ –∑–∞–¥–∞—á–µ.
3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞, –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ LR , –∞ —Ç–∞–∫–∂–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ –∑–∞–¥–∞—á—É –Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π.
4. –î–µ–ª–∞–µ–º finetuning –ø–æ–¥ –Ω–∞—à—É –∑–∞–¥–∞—á—É. –ú–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è, –∑–∞–º–æ—Ä–æ–∑–∏–≤ –ø—Ä–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏–ª–∏ –∂–µ –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ end-to-end –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –≤—Å–µ—Ö –∏–º–µ—é—â–∏—Ö—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

–ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ï—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã ‚Äî –Ω–∞ –Ω–∞—á–∞–ª—å–Ω–æ–º —ç—Ç–∞–ø–µ –≤–∞—Ä—å–∏—Ä—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

- –≤—ã–±–æ—Ä LR, weight decay, –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ LR;
- –≤—ã–±–æ—Ä –Ω–∞–±–æ—Ä–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π.

### –î–∏–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã –±—ã–ª —Å–æ—Å—Ç–∞–≤–ª–µ–Ω —Å–ª–µ–¥—É—é—â–∏–π –¥–∏–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:

1. –í –∫–∞—á–µ—Å—Ç–≤–µ **–ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏** –∞–≤—Ç–æ—Ä—ã –±–µ—Ä—É—Ç CLIP ViT-B/32 (OpenAI).
2. –í –∫–∞—á–µ—Å—Ç–≤–µ **—Ü–µ–ª–µ–≤–æ–≥–æ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö** ‚Äî ImageNet.
3. –í –∫–∞—á–µ—Å—Ç–≤–µ **–Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏** ‚Äî ImageNet-V2, R, Scetch, A –∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ObjectNet.
4. –¢–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **end-to-end** –∫–∞–∫ ****–≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–æ–±—É—á–µ–Ω–∏—è (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—è –≤—Å–µ –∏–º–µ—é—â–∏–µ—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã).
5. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç **—Å–ª—É—á–∞–π–Ω—ã–π seed** –∏ **–ø–æ—Ä—è–¥–æ–∫ –¥–∞–Ω–Ω—ã—Ö**.
6. –°–µ–º–ø–ª–∏—Ä—É—é—Ç **—Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** –¥–ª—è:
    - LR;
    - Weight decay;
    - Augmentation strength;
    - Mixup;
    - Label smoothing.

–ß—É—Ç—å –ø–æ–∑–∂–µ –º—ã –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ –≤–ª–∏—è–Ω–∏–∏ –∑–Ω–∞—á–µ–Ω–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è. –ê —Å–µ–π—á–∞—Å —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –º–µ—Ç–æ–¥—ã —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –æ—Ç –∞–≤—Ç–æ—Ä–æ–≤ —Å—Ç–∞—Ç—å–∏. –ö–∞–∂–¥—ã–π —Ç–∞–∫–æ–π –º–µ—Ç–æ–¥ –ª–∞–∫–æ–Ω–∏—á–Ω–æ –Ω–∞–∑–≤–∞–Ω **Recipe** (—Ä–µ—Ü–µ–ø—Ç).

### –†–µ—Ü–µ–ø—Ç—ã, –∏–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ—Ä—ã –≤–æ –≤—Ä–µ–º—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–π –Ω–∞–±–æ—Ä —Ä–µ—Ü–µ–ø—Ç–æ–≤:

- **Uniform soup** $f(x,\frac{1}{k}\sum^{k}_{i=1}\theta_{i})$ ‚Äî average –≤–µ—Å–æ–≤ –≤—Å–µ—Ö –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π;
- **Greedy soup** $\textbf{Recipe 1}$ ‚Äî –≤—ã–±–æ—Ä–æ—á–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ;
- **Learned soup** $\textbf{Recipe 2}$ ‚Äî —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –≤—ã—É—á–µ–Ω–Ω—ã–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º.

$\textbf{Recipe 1 : GreedySoup}$

$\textbf{Input}: \text{–ù–∞–±–æ—Ä —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ —Å—É–ø–∞)}:\ \{{\theta_{1}}, ..., {\theta_{k}}\}$

$\text{–≥–¥–µ}\ \{{\theta_{1}}, ..., {\theta_{k}}\} - \text{–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏}$ $\text{ValAcc}({\theta_{i}})$

$\text{ingredients} ‚Üê \{\} - \text{—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤}$

$\textbf{for}\ \text{i = 1}\ \textbf{to}\ \text{k}\ \textbf{do} :$
${if} \space {ValAcc}({average}({ingredients} ‚à™ {\theta_{i}})) ‚â• {ValAcc}({average}({ingredients}))$
${then}\space {ingredients} ‚Üê {ingredients} ‚à™ {\theta_{i}}$ 

$\textbf{return}\ \text{average}(\text{ingredients})$

**–ñ–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º**, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –∞–≤—Ç–æ—Ä–∞–º–∏, –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –ø–µ—Ä–µ–±–æ—Ä–µ –≤—Å–µ—Ö –∏–º–µ—é—â–∏—Ö—Å—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è –∏—Ö —Ç–æ—á–Ω–æ—Å—Ç–∏. –¢–æ –µ—Å—Ç—å –º—ã –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞–∏–ª—É—á—à–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –∏ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —É—Å—Ä–µ–¥–Ω—è–µ–º –∏ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–ª—É—á—à–∞—é—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –∏—Ç–æ–≥–æ–≤—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:**

- –æ–Ω –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã;
- —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É—Ö—É–¥—à–∞—é—Ç –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ ‚Äú—Å—É–ø‚Äù: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏—Ç–æ–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Ä–∞–≤–µ–Ω —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞:**

- —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ —Å—É–±–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞, –≤–µ–¥—å –º—ã –Ω–µ –∏—Å—Å–ª–µ–¥—É–µ–º –¥—Ä—É–≥–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤, –∫—Ä–æ–º–µ –ø–µ—Ä–µ–±–æ—Ä–∞ –ø–æ —É–º–µ–Ω—å—à–µ–Ω–∏—é —Ç–æ—á–Ω–æ—Å—Ç–∏;
- —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö —Ç–æ—á–Ω–æ—Å—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Ä–∞—Å—Ç–µ—Ç, –º–æ–≥—É—Ç –∏ –Ω–µ —É–ª—É—á—à–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ out-of-distribution –¥–∞–Ω–Ω—ã—Ö.


$\textbf{Recipe 2 : LearnedSoup}$

$\textbf{Input}: \text{–ù–∞–±–æ—Ä —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ —Å—É–ø–∞)}:\ \{{\theta_{1}}, ..., {\theta_{k}}\}$

$\text{–û–±—É—á–∞–µ–º—ã–π –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤}: W^{1\times k}_{soup}, \beta - \text{–ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã}, \\E - \text{–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π}$

${(x_{j}, y_{j})}^n_{j=1} - \text{ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç}$

$\textbf{for}\ \text{e = 1}\ \textbf{to}\ \text{E}\ \textbf{do} :$

$\alpha^{e} = softmax(W^{e}_{soup})$ ‚Äî –≤–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ª–∏–Ω–µ–π–Ω–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π

$\mathit{scores} = f(x_{j},\sum^{k}_{i=1}\alpha^e_{i}\theta_{i})$ ‚Äî –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏, –ø–æ–ª—É—á–µ–Ω–Ω–æ–π —Å –≤–µ—Å–∞–º–∏ $\alpha^{e}$

$l^e = \sum^n_{j=1}L(Œ≤ ¬∑ \mathit{scores},y_{j})$ ‚Äî –æ—à–∏–±–∫–∞ –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

$W^{e+1}_{soup} = {W^{e}_{soup}} -\eta\frac{\partial l^e}{\partial W^{e}_{soup}}$ , –≥–¥–µ $\eta$ ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è

–ü—Ä–∏ –ø–æ–¥–±–æ—Ä–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $W^{e}_{soup}$ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã $\{{\theta_{1}}, ..., {\theta_{k}}\}$ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã. –ï—â–µ –∞–≤—Ç–æ—Ä—ã —Å–æ–æ–±—â–∞—é—Ç: –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –º–æ–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å –≤–µ—Å–∞ –Ω–µ –¥–ª—è –≤—Å–µ–π –º–æ–¥–µ–ª–∏, –∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–ª–æ—è.

**–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å:** –ø–æ–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂ –Ω–∞ –ø–æ–¥–±–æ—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –≤–æ –≤—Ä–µ–º—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∞–Ω—Å–∞–º–±–ª—è–º–∏.


### –°–ø—Ä–∞–≤–∫–∞ –ø–æ —Ä–µ—Ü–µ–ø—Ç–∞–º
- **Uniform soup** –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å —Å—Ä–µ–¥–∏ —Ä–µ—Ü–µ–ø—Ç–æ–≤, –Ω–æ —É—Ö—É–¥—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–¥–∞—á–µ;
- **Greedy soup** –¥–∞–µ—Ç 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–∞–∏–ª—É—á—à–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –≤—ã–±–æ—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤;
- –ü–æ—Ä—è–¥–æ–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π –≤ **Greedy soup** –≤–ª–∏—è–µ—Ç –Ω–∞ –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –≤ 0.05 –∏ 0.16 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ;
- –ù–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª—É—á–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é **Learned Soup** (–ø–æ—Å–ª–æ–π–Ω–æ–≥–æ), –Ω–æ –æ–Ω —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥–±–æ—Ä–∞ NxM –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –≥–¥–µ N ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –∞ M ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤.
### –ü–æ—á–µ–º—É —Ä–∞–±–æ—Ç–∞–µ—Ç?
–í —Å—Ç–∞—Ç—å–µ ‚Äú[Taxonomizing local versus global structure in neural network loss landscapes](https://arxiv.org/abs/2107.11228)‚Äù –∞–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤. –î–∏–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö, –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –¥—Ä.) –∑–¥–µ—Å—å –æ–±—É—Å–ª–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –Ω–∏—Ö.

![[Pasted image 20240408155636.png]]
–ü–æ–¥–æ–±–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã –≤ —Å—Ç–∞—Ç—å–µ Model Soups –∞–≤—Ç–æ—Ä—ã –Ω–∞–∑—ã–≤–∞—é—Ç **Basin (–≤–ø–∞–¥–∏–Ω–∞).**

> **Basin** ‚Äî –ª–æ–∫–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –≤ –∫–æ—Ç–æ—Ä–æ–µ –º—ã –ø–æ–ø–∞–¥–∞–µ–º –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

–ï—Å—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤:

1. **Globally poorly-connected**
    1. **Phase I** ‚Äî –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ —Å–∏–ª—å–Ω–æ –∫–æ–ª–µ–±–ª–µ—Ç—Å—è, —Ä–∞–∑–ª–∏—á–Ω—ã–µ –±–∞–∑–∏–Ω—ã –ø–ª–æ—Ö–æ —Å–≤—è–∑–∞–Ω—ã;
    2. **Phase III** ‚Äî –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –∫–æ–ª–µ–±–∞–Ω–∏—è –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, —Ä–∞–∑–ª–∏—á–Ω—ã–µ –±–∞–∑–∏–Ω—ã –≤—Å–µ –µ—â–µ –ø–ª–æ—Ö–æ —Å–≤—è–∑–∞–Ω—ã.
2. **Globally well-connected**
    1. **Phase II** ‚Äî –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –∫–æ–ª–µ–±–∞–Ω–∏—è –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Ä–∞–∑–ª–∏—á–Ω—ã–µ –±–∞–∑–∏–Ω—ã —Å–≤—è–∑–∞–Ω—ã, –Ω–æ –Ω–∞ –ø—É—Ç–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ñ–ª—É–∫—Ç—É–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏;
    2. **Phase IV-A,B** ‚Äî –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –∫–æ–ª–µ–±–∞–Ω–∏—è –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–π —Ç–æ—á–∫–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, —Ä–∞–∑–ª–∏—á–Ω—ã–µ –±–∞–∑–∏–Ω—ã —Ö–æ—Ä–æ—à–æ —Å–≤—è–∑–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π.
–ê–≤—Ç–æ—Ä—ã Model Soups –æ—Ç–º–µ—á–∞—é—Ç: –∏—Ö –ø–æ–¥—Ö–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –ª–µ–∂–∞—Ç –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π –±–∞–∑–∏–Ω—ã (–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –≤–∞—Ä–∏–∞–Ω—Ç—ã Phase IV-A –∏ Phase IV-B)

–ß—Ç–æ–±—ã —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è, –∫–∞–∫ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å —Ä–∞—Å–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –∏—Ç–æ–≥–æ–≤–∞—è —Ç–æ—á–∫–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏), –æ–±—Ä–∞—Ç–∏–º—Å—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –¥–≤—É—Ö —Ä–∞–±–æ—Ç: ‚Äú[Deep Ensembles: A Loss Landscape Perspective](https://arxiv.org/abs/1912.02757)‚Äù –∏ ‚Äú[Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel](https://arxiv.org/abs/2010.15110)‚Äù.

–í –ø–µ—Ä–≤–æ–π —Ä–∞–±–æ—Ç–µ –∞–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç **–¥–∏–Ω–∞–º–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π** –ø—Ä–∏ —Ä–∞–∑–Ω–æ–π –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ **—Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ç–æ—á–µ–∫ –≤–µ—Å–æ–≤** –≤ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.

–ê–≤—Ç–æ—Ä—ã –∑–∞–ø—É—Å–∫–∞—é—Ç –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω–æ–π –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
–ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å —Ä–∞–∑–ª–∏—á–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –æ–±–µ –º–æ–¥–µ–ª–∏ —Å—Ö–æ–¥—è—Ç—Å—è –∫ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º(–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏) –∑–Ω–∞—á–µ–Ω–∏—è–º –æ—à–∏–±–∫–∏, –Ω–æ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è. –°–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –±–∞–∑–∏–Ω–∞—Ö. –ö —Ç–∞–∫–∏–º –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø—Ä–∏—à–ª–∏ –∏ –≤ —Å—Ç–∞—Ç—å–µ ‚Äú[Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs](https://arxiv.org/abs/1802.10026)‚Äù, –≥–¥–µ –ø—Ä–æ–≤–µ–ª–∏ 3 –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–æ —Å–ª—É—á–∞–π–Ω–æ–π –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–≤ –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ, –∞–≤—Ç–æ—Ä—ã –ø–æ–ª—É—á–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
![[Pasted image 20240408155952.png]]–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—É—á–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Å—Ö–æ–∂–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º –æ—à–∏–±–∫–∏, –Ω–æ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –º—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±–∞–∑–∏–Ω–∞—Ö. –ò—Å—Ö–æ–¥—è –∏–∑ —ç—Ç–æ–≥–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤—ã–≤–æ–¥: –ø—Ä–∏ **—Ä–∞–±–æ—Ç–µ —Å –º–µ—Ç–æ–¥–æ–º Model Soups –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—É—é –Ω–∞—á–∞–ª—å–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é, –∏–Ω–∞—á–µ –º—ã –Ω–µ –ø–æ–ª—É—á–∏–º –Ω—É–∂–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π.**

–¢–µ–ø–µ—Ä—å —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã ‚Äú[Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel](https://arxiv.org/abs/2010.15110)‚Äù. –í –Ω–µ–π –∞–≤—Ç–æ—Ä—ã –∏—Å—Å–ª–µ–¥—É—é—Ç —ç–≤–æ–ª—é—Ü–∏—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Å –ø–æ–º–æ—â—å—é Neural Tangent Kernel. –ü–æ–º–∏–º–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–≤—Ç–æ—Ä—ã —Ç–∞–∫–∂–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç —Ä–µ–∂–∏–º, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º —É –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –Ω–∞—á–∞–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è. –û–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å–ª–µ–¥—É—é—â–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
![[Pasted image 20240408160600.png]]–ú—ã –≤–∏–¥–∏–º –¥–≤–∞ —Å–∏–º–ø–ª–µ–∫—Å–∞ —Å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –Ω–∞ –Ω–∏—Ö —Ç–æ—á–∫–∞–º–∏. –ì—Ä–∞–Ω–∏—Ü—ã —Å–∏–º–ø–ª–µ–∫—Å–∞ (—á–µ—Ä–Ω–∞—è –ª–∏–Ω–∏—è) ‚Äî —Ä–µ–≥–∏–æ–Ω—ã —Å –Ω–∏–∑–∫–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –æ—à–∏–±–∫–∏, –±–µ–ª—ã–º —Ü–≤–µ—Ç–æ–º —É–∫–∞–∑–∞–Ω —Ä–µ–≥–∏–æ–Ω —Å –≤—ã—Å–æ–∫–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –æ—à–∏–±–∫–∏.

**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç A**

–ê–≤—Ç–æ—Ä—ã –∑–∞–ø—É—Å–∫–∞—é—Ç –¥–≤–∞ –æ–±—É—á–µ–Ω–∏—è –æ–¥–Ω–æ–π –∏ —Ç–æ–π –∂–µ –º–æ–¥–µ–ª–∏, –Ω–æ —Å —Ä–∞–∑–ª–∏—á–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è ‚Äî –∫—Ä–∞—Å–Ω—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö —Å–∏–º–ø–ª–µ–∫—Å–∞. –û—Ä–∞–Ω–∂–µ–≤—ã–º —Ü–≤–µ—Ç–æ–º –ø–æ–∫–∞–∑–∞–Ω –ª–∏–Ω–µ–π–Ω—ã–π –ø—É—Ç—å –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫ –¥—Ä—É–≥–æ–π. –ö–∞–∫ –∏ –≤ —Ä–∞–Ω–µ–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö, —Ç–∞–∫–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤—ã—Å–æ–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏, –ø–æ—ç—Ç–æ–º—É –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–π –ø—É—Ç—å (–∂–µ–ª—Ç—ã–π —Ü–≤–µ—Ç).

**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç B**
–ê–≤—Ç–æ—Ä—ã –∑–∞–ø—É—Å–∫–∞—é—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ —Ä–µ–∂–∏–º–µ, –ø–æ—Ö–æ–∂–µ–º –Ω–∞ Model Soups. –û–Ω–∏ —Å—Ç–∞—Ä—Ç—É—é—Ç –æ—Ç —Å–∏–Ω–µ–π —Ç–æ—á–∫–∏ –∏ —Å–µ–º–ø–ª–∏—Ä—É—é—Ç –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö –æ–±—É—á–µ–Ω–∏—è –ø–æ –¥–≤–µ –º–æ–¥–µ–ª–∏ –≤ –∑–µ–ª–µ–Ω—ã—Ö —Ç–æ—á–∫–∞—Ö. –°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–æ—É—á–∏–≤–∞—é—Ç—Å—è –¥–æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –∏—Ö –æ–±–æ–∑–Ω–∞—á–∞—é—Ç –∫—Ä–∞—Å–Ω—ã–º–∏ —Ç–æ—á–∫–∞–º–∏ –Ω–∞ —Å–∏–º–ø–ª–µ–∫—Å–µ. –ö–∞–∫ –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤—ã—à–µ, –¥–ª—è —Ä–∞–Ω–Ω–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–ø–µ—Ä–≤–∞—è –∑–µ–ª–µ–Ω–∞—è —Ç–æ—á–∫–∞) –æ–Ω–∏, –∫–∞–∫ –∏ –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ –ê, –Ω–∞—Ö–æ–¥—è—Ç—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü–∞—Ö —Å–∏–º–ø–ª–µ–∫—Å–∞. –ù–æ –µ—Å–ª–∏ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ –ø–æ–∑–∂–µ ‚Äî –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –±—É–¥—É—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –æ–¥–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü–µ —Å–∏–º–ø–ª–µ–∫—Å–∞. –¢–æ–≥–¥–∞ –º–µ–∂–¥—É –Ω–∏–º–∏ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ª–∏–Ω–µ–π–Ω—É—é –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π –∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤–æ –≤—Å–µ—Ö —Ç–æ—á–∫–∞—Ö –Ω–∞ –ø—É—Ç–∏ –±—É–¥–µ—Ç –Ω–∏–∑–∫–∏–º.

–ò–∑—É—á–∏–≤ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –º—ã –ø—Ä–∏—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–∏–º –≤—ã–≤–æ–¥–∞–º:

- –Ω—É–∂–Ω–∞ **–∏–¥–µ–Ω—Ç–∏—á–Ω–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è** (–≤ —Ü–µ–ª–æ–º —Å–ª–µ–¥—É–µ–º –ø–æ–¥—Ö–æ–¥—É –∏–∑ Model Soups);
- –Ω—É–∂–Ω–∞ **–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å**, —Å –∫–æ—Ç–æ—Ä–æ–π –º—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º—Å—è (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥–∞–ª–µ–µ);
- –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ **–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è**, –≤–µ–¥—å –æ–Ω–∏ –≤–ª–∏—è—é—Ç –Ω–∞ —Ç–µ –º–∏–Ω–∏–º—É–º—ã, –≤ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø–∞–¥–µ—Ç –º–æ–¥–µ–ª—å.

### Mode connectivity and Linear mode connectivity

**Mode connectivity**

–í —Ä–∞–º–∫–∞—Ö —Ä–∞–±–æ—Ç—ã —Å –≥–ª—É–±–æ–∫–∏–º–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏ –∞–Ω–∞–ª–∏–∑ —Å–≤–æ–π—Å—Ç–≤ —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≤–µ—Å–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –±—ã–ª –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ —Å—Ç–∞—Ç—å–µ ["Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs"](https://arxiv.org/abs/1802.10026) –∏ ["Essentially No Barriers in Neural Network Energy Landscape"](https://arxiv.org/abs/1803.00885). –ó–¥–µ—Å—å –∞–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏ –º–µ–∂–¥—É –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏, –Ω–∞—Ö–æ–¥—è—â–∏–º–∏—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö –±–∞–∑–∏–Ω–∞—Ö. –ò–∑–Ω–∞—á–∞–ª—å–Ω–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ —Ç—Ä–µ–±–æ–≤–∞–ª–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–∞–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞ –≤—Å–µ–º –µ–≥–æ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–∞—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—à–∏–±–∫–∏ –±—É–¥–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º. –ò—Å–ø–æ–ª—å–∑—É—è Bezier –∏ Polychain –∫—Ä–∏–≤—É—é, –∞–≤—Ç–æ—Ä—ã –∑–∞ —Å—á–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–º–µ—â–µ–Ω–∏—è –≤–µ—Å–æ–≤ –≤–¥–æ–ª—å —ç—Ç–∏—Ö –∫—Ä–∏–≤—ã—Ö –ø—Ä–∏—Ö–æ–¥—è—Ç –∫ —Å–ª–µ–¥—É—é—â–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º (–ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± —ç—Ç–æ–º ‚Äî –≤ [–≤–∏–¥–µ–æ](https://youtu.be/37wntPh_24Y?si=ZzoPlMxcTdrDJ8ZR&t=1649) –æ—Ç –∞–≤—Ç–æ—Ä–∞ —Å—Ç–∞—Ç—å–∏):
![[Pasted image 20240408161602.png]]
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–≤—É—Ö —Ä–∞–±–æ—Ç –æ—Ç–ª–∏—á–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–º—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–∞–∫–∏—Ö –ø—É—Ç–µ–π –º–µ–∂–¥—É –≤–µ—Å–∞–º–∏ –∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤ —Å—Ç–∞—Ç—å–µ **‚Äú[Learning Neural Network Subspaces](https://arxiv.org/abs/2102.10472)‚Äù.**

–ü—Ä–∏ –≤—Å–µ–º —É—Å–ø–µ—Ö–µ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Ä–∞–±–æ—Ç—ã Model Soups –Ω—É–∂–Ω–∞ –ª–∏–Ω–µ–π–Ω–∞—è —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –≤–µ—Å–æ–≤. –ü–æ—ç—Ç–æ–º—É –¥–∞–≤–∞–π—Ç–µ –æ–±—Ä–∞—Ç–∏–º—Å—è –∫ **Linear mode connectivity.**


**Linear mode connectivity** 
–ê –µ—Å–ª–∏ –º—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ (–∫–∞–∫, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ Model Soups) –∏ –∑–∞—Ö–æ—Ç–µ–ª–∏ –ø–æ–Ω—è—Ç—å, —Å—Ö–æ–¥—è—Ç—Å—è –ª–∏ –æ–Ω–∏ –≤ –æ–¥–Ω—É –±–∞–∑–∏–Ω—É –∏–ª–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –∫ —Ä–∞–∑–Ω—ã–º? –ê–≤—Ç–æ—Ä—ã —Å—Ç–∞—Ç—å–∏ ["Linear Mode Connectivity and the Lottery Ticket Hypothesis"](https://arxiv.org/abs/1912.05671) —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–æ–±–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

**–ü—É—Å—Ç—å –Ω–∞–º –¥–∞–Ω–æ:**

- $\mathit{N}$ ‚Äî –º–æ–¥–µ–ª—å
- $\mathit{W}$ ‚Äî –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
- $\mathit{SGD}$ ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
- $\mathit{U}$ ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —à—É–º–∞ (—Å—é–¥–∞ –≤—Ö–æ–¥–∏—Ç –Ω–∞–±–æ—Ä –∞–≥—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–∞—Ç—á–µ–π –∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–∂–µ–º –∑–∞–¥–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ)

**–ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å:**

–ö–∞–∫–æ–≤–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å $\mathit{SGD}$ –∫ —Å–ª—É—á–∞–π–Ω–æ–º—É —à—É–º—É, —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∏–∑ $\mathit{U}$ ? –ó–¥–µ—Å—å –ø–æ–¥ **—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å—é** –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç—Å—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –≤–µ—Å–∞–º–∏ $\mathit{W}_1$ –∏ $\mathit{W}_2$, –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å–µ–º–ø–ª–∞–º–∏ —à—É–º–∞ –∏–∑ $\mathit{U}$.

$$
\mathcal{E_{a}}(W_{1}, W_{2}) = \mathcal{E}(aW_{1} + (1‚àía)W_{2}) \\ \space –≥–¥–µ \space \\ W_{1}, W_{2} - –≤–µ—Å–∞\ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö\ –º–æ–¥–µ–ª–µ–π \\ \space  \mathcal{E} - –∑–Ω–∞—á–µ–Ω–∏–µ\ –æ—à–∏–±–∫–∏\\ \space  a \in [0,1] - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç\ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏
$$

–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∞–≤—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–ª–∏–≤–∞—é—Ç —Å–≤–µ—Ç –Ω–∞ –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ Model Soups.
1. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å 0: —É –Ω–∏—Ö –∏–¥–µ–Ω—Ç–∏—á–Ω–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –∏–Ω—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
	1.–°–æ–≥–ª–∞—Å–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ:
	- –¥–ª—è —Å–µ—Ç–∏ LeNet –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ MNIST –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å SGD —è–≤–ª—è–µ—Ç—Å—è —É—Å—Ç–æ–π—á–∏–≤–æ–π –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º —à—É–º–∞–º –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–π –±–∞–∑–∏–Ω–µ;
	- –¥–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –æ–±—É—á–µ–Ω–∏–µ —Å –æ–±—â–µ–π —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π —Å–≤–æ–¥–∏—Ç—Å—è –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º –±–∞–∑–∏–Ω–∞–º.
2. –∑–∞ –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ $\mathit{W}$ –±–µ—Ä–µ—Ç—Å—è —á–µ–∫–ø–æ–∏–Ω—Ç –ø–æ—Å–ª–µ k –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è, –∏ –∫–∞–∂–¥–∞—è –∏–∑ —Å–µ—Ç–µ–π –¥–æ—É—á–∏–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ª–µ–¥—É—é—â–∏–µ:
	1. –°–æ–≥–ª–∞—Å–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ:
		- –¥–ª—è —Å–µ—Ç–∏ LeNet –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ MNIST –∑–Ω–∞—á–µ–Ω–∏–µ k –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —à—É–º—É;
		- –¥–ª—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö CIFAR-10 –∏ —Å–µ—Ç–µ–π ResNet-20 –∏ VGG-16 —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–∞–µ—Ç, –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –∏–Ω—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Å –≤–µ—Å–æ–≤ –ø—Ä–∏ k ‚â• 2000 –¥–ª—è ResNet –∏ k‚â•1000 –¥–ª—è VGG (—á—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ 3 –∏ 1.5 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –æ—Ç –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ batch size = 128);
		- –¥–ª—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö ImageNet –¥–ª—è —Å–µ—Ç–∏ ResNet-50 —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Å 18 —ç–ø–æ—Ö–∏ (20% –æ—Ç –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è (90 —ç–ø–æ—Ö) –ø—Ä–∏ batch size = 1024), –¥–ª—è Inception-v3 ‚Äî —Å 28 —ç–ø–æ—Ö–∏ (16%, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö —Ä–∞–≤–Ω–æ 171).
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –Ω–∞ –∫–∞–∫–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∏–∑ ‚Äúearly chaotic‚Äù –∫ ‚Äúlate stable‚Äù.


–ò—Å—Ö–æ–¥—è –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –≤—ã–≤–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ Model Soups:

1. –î–ª—è –∫—Ä–æ—à–µ—á–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö (MNIST) –¥–∞–∂–µ —Å–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª–∏—Ç –ø–æ–ª—É—á–∏—Ç—å –ª–∏–Ω–µ–π–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –≤–µ—Å–∞.
2. –° —Ä–æ—Å—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —Ä–∞—Å—Ç–µ—Ç –∏ —Ç—Ä–µ–±—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è (–Ω–∞—á–∏–Ω–∞—è –æ—Ç 3% –¥–ª—è CIFAR-10 –∏ –¥–æ 20% –Ω–∞ ImageNet).

–¢–µ–ø–µ—Ä—å, –æ–±–ª–∞–¥–∞—è –∑–Ω–∞–Ω–∏—è–º–∏ –æ —Å–≤–æ–π—Å—Ç–≤–∞—Ö —Ä–∞–±–æ—Ç—ã Model Soups, –≤–∑–≥–ª—è–Ω–µ–º –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ **SWA** –∏ –ø–æ–π–º–µ–º, –≤ —á–µ–º —Å–≤—è–∑—å –∏ –æ—Ç–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ (—Ä–∞–Ω–µ–µ —É –Ω–∞—Å –≤—ã—Ö–æ–¥–∏–ª–∞ —Å—Ç–∞—Ç—å—è [Weight Averaging](https://www.notion.so/07a2c80c6cf54858887d71fac70d8a31?pvs=21) –ø—Ä–æ –±–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ **SWA** –∏ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—é –≤ –∫–æ–¥–µ).

### Model Soups VS Stohastic Weight Averaging. –ê –≤ —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞?
–ö—Ä–∞—Ç–∫–æ —Å—É–º–º–∏—Ä—É–µ–º [SWA](https://arxiv.org/abs/1803.05407). –ü–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è:

- $\mathit{N}$ ‚Äî –º–æ–¥–µ–ª—å
- $\mathit{W}$ ‚Äî –ø—Ä–æ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
- $\mathit{SGD}$ ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
- $\mathit{Cycle\ lenght}$ ‚Äî –¥–ª–∏–Ω–∞ —Ü–∏–∫–ª–∞ –ø—Ä–∏ —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏ LR (–ø—Ä–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω–æ–º = 1)
- $\mathit{E_n}$ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–æ–æ–±—É—á–µ–Ω–∏—è

–ò–º–µ–Ω–Ω–æ —Å —Ä–∞–Ω–µ–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (75% –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –¥–ª—è CIFAR-10 –∏ –°IFAR-100 , –¥–ª—è Imagenet —Å –ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –∏–∑ torchvision) –∞–≤—Ç–æ—Ä—ã –Ω–∞—á–∏–Ω–∞—é—Ç –ø—Ä–æ—Ü–µ—Å—Å SWA. –ü—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–≤–∞ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–∂–Ω–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ö–µ–º–æ–π:

![[Pasted image 20240408162712.png]]

–ü—Ä–∏ –∫–∞–∂–¥–æ–º –æ–∫–æ–Ω—á–∞–Ω–∏–∏ —Ü–∏–∫–ª–∞ (–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ–Ω –æ—Ç–º–µ—á–µ–Ω –æ—Ä–∞–Ω–∂–µ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏) –∞–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç —Å–ª–µ–¥—É—é—â—É—é —Ñ–æ—Ä–º—É–ª—É –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤:
$$
W_{\mathit{SWA}} ‚Üê \frac{W_{\mathit{SWA}}¬∑n_{\mathit{models}}+W}{ n_\mathit{models}+1}
$$
$–≥–¥–µ\ W - –≤–µ—Å–∞\ –ø–æ—Å–ª–µ\ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ\ —à–∞–≥–∞\ –≤\ —Ç–æ—á–∫–µ\ –æ–∫–æ–Ω—á–∞–Ω–∏—è\ —Ü–∏–∫–ª–∞\ n_{\mathit{models}} - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö\ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\ \ W_{\mathit{SWA}} - —Ç–µ–∫—É—â–∏–π\ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è$

**–í–∞–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å**: –ø–æ—Å–∫–æ–ª—å–∫—É –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤–µ—Å–∞, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –º—ã –º–æ–∂–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –Ω–∞—Ö–æ–¥–∏–º—Å—è –≤ –æ–¥–Ω–æ–π –±–∞–∑–∏–Ω–µ. –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Å–æ–±—ã–π –≤–∏–¥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç—å —ç—Ç–æ–π –±–∞–∑–∏–Ω—ã.

–î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å–≤–æ–π—Å—Ç–≤–∞ —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è ‚Äî –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ SWA.

**–¶–∏–∫–ª–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è** –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ª–∞–Ω–¥—à–∞—Ñ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∫–∞–∫ –ª–æ–∫–∞–ª—å–Ω–æ (–≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π –±–∞–∑–∏–Ω—ã), —Ç–∞–∫ –∏ –±–æ–ª–µ–µ –≥–ª–æ–±–∞–ª—å–Ω–æ (–ø—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω–æ–≤—ã—Ö –±–∞–∑–∏–Ω).
![[Pasted image 20240408163020.png]]–ö–∞–∫ –≤–∏–¥–Ω–æ –∏–∑ —Ä–∏—Å—É–Ω–∫–∞ –≤—ã—à–µ (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∞–≤–æ–π —á–∞—Å—Ç–∏), –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –ø–µ—Ä–µ—Ö–æ–¥—É –≤ –¥—Ä—É–≥–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å (–≤ –¥—Ä—É–≥—É—é –±–∞–∑–∏–Ω—É) –∏ –¥–æ –∫–æ–Ω—Ü–∞ —Ü–∏–∫–ª–∞, –ø–æ–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —Å–Ω–∏–∂–∞–µ—Ç—Å—è, –º–æ–¥–µ–ª—å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å—Ö–æ–¥–∏—Ç—Å—è –∫ –º–∏–Ω–∏–º—É–º—É —ç—Ç–æ–π –±–∞–∑–∏–Ω—ã (–∏–∑–º–µ–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Å—Ç—Ä–µ–ª–∫–∏). –° –ø–æ–º–æ—â—å—é —Ç–∞–∫–æ–≥–æ –ø—Ä–∏–µ–º–∞ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞–ª–∏ –∞–≤—Ç–æ—Ä—ã ‚Äú[Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs](https://arxiv.org/abs/1802.10026)‚Äù –∏ "[Snapshot Ensembles: Train 1, get M for free](https://arxiv.org/abs/1704.00109)‚Äù. –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ —á–µ—Ä–µ–∑ Linear mode connectivity –∞–≤—Ç–æ—Ä—ã —Å—Ç–∞—Ç—å–∏ ‚Äú[Exploring loss function topology with cyclical learning rates](https://arxiv.org/abs/1702.04283)‚Äù. –ø–æ–ª—É—á–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

![[Pasted image 20240408163107.png]]–ü—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ –æ—Ç 0 –¥–æ 1 –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–∫–∏. –í —Ä–µ–∂–∏–º–µ —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º—ã –∏–º–µ–µ–º —Ä–µ–∑–∫–æ–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ a = 0.5, —á—Ç–æ —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–∏ –≤–µ—Å–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö –±–∞–∑–∏–Ω–∞—Ö. –¢—É—Ç –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –≤–æ–ø—Ä–æ—Å: –ø–æ—á–µ–º—É –ø—Ä–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–∏ –ø–æ —Ç–∞–∫–∏–º —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º –≤ SWA —É –Ω–∞—Å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∏—Ç–æ–≥–æ–≤—ã–π —Ä–æ—Å—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ? –ï—Å—Ç—å —Ä—è–¥ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –ø–µ—Ä–µ–π—Ç–∏ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π:
- —Å—Ç–∞—Ä—Ç —Å –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö;
- –∫–æ—Ä–æ—Ç–∫–∏–π —Ü–∏–∫–ª ‚Äî –≤ SWA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ü–∏–∫–ª –∏–∑ 5 —ç–ø–æ—Ö, –∞ –≤ SSE ‚Äî –æ—Ç 20 –¥–æ 50 —ç–ø–æ—Ö (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏);
- –∑–Ω–∞—á–µ–Ω–∏–µ LR –¥–ª—è —Ü–∏–∫–ª–∞ ‚Äî –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã SWA –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø—Ä–∏ –∑–Ω–∞—á–µ–Ω–∏—è—Ö –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ LR = 5 ¬∑ 10‚àí2 –∏ 5 ¬∑ 10‚àí4 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, —Ç–æ–≥–¥–∞ –∫–∞–∫ –≤ Snapshot Ensembles –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 1 * 10-1 –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ.
–ö–∞–∫ –≤–∏–¥–Ω–æ –∏–∑ —Ä–∏—Å—É–Ω–∫–∞ –≤—ã—à–µ, –∑–Ω–∞—á–µ–Ω–∏–µ LR —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã SWA.

–ò—Ç–∞–∫, –æ—Å—Ç–∞–Ω–æ–≤–∏–º—Å—è –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ SWA –∏ Model Soups:

**Model Soups**

- —Å—Ç–∞—Ä—Ç—É–µ–º —Å –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –Ω–∞—á–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ—à–ª–∞—Å—å
- N –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –¥–æ–æ–±—É—á–µ–Ω–∏–π
- –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –±–∞–∑–∏–Ω—ã –∑–∞ —Å—á–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞ (–ø–æ—Ä—è–¥–æ–∫ –±–∞—Ç—á–µ–π, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∑–Ω–∞—á–µ–Ω–∏–µ LR)
- –µ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**SWA**

- —Å—Ç–∞—Ä—Ç—É–µ–º —Å –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –Ω–∞—á–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ—à–ª–∞—Å—å
- –æ–¥–Ω–æ –¥–æ–ª–≥–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ
- –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –±–∞–∑–∏–Ω—ã –∑–∞ —Å—á–µ—Ç –≤–∞—Ä—å–∏—Ä–æ–≤–∞–Ω–∏—è LR
- –µ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

–§–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: –∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è Model Soups? –î–ª—è –æ—Ç–≤–µ—Ç–∞ –æ–±—Ä–∞—Ç–∏–º—Å—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Å—Ç–∞—Ç—å–∏ ‚Äú[To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning](https://arxiv.org/abs/2303.03374)‚Äù, –∞–≤—Ç–æ—Ä—ã –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–≤–µ–ª–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–µ–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∫–∞–∫ –ø–æ –∞–Ω–∞–ª–∏–∑—É –∞–Ω—Å–∞–º–±–ª–µ–π –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏, —Ç–∞–∫ –∏ –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä–∞–±–æ—Ç—ã Model Soups. –û–Ω–∏ –ø–æ–º–æ–≥—É—Ç –ø–æ–Ω—è—Ç—å, –∫–∞–∫–æ–π —Ä–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –±—É–¥–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π.

### –ò—Å—Å–ª–µ–¥—É–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –±–∞–∑–∏–Ω—ã: –≤–ª–∏—è–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–±—É—á–µ–Ω–∏—è
–ù–∞—á–Ω–µ–º —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏. –ê–≤—Ç–æ—Ä—ã —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç –µ–µ –≤ –≤–∏–¥–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: –∫–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –∫ –¥–æ–æ–±—É—á–µ–Ω–∏—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å, —á—Ç–æ–±—ã –∏–∑ N –¥–æ–æ–±—É—á–µ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π? –ü—Ä–∏ —ç—Ç–æ–º –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ —Ç–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –º–æ–≥ –±—ã –ø–æ–∑–≤–æ–ª–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU —á–∞—Å–æ–≤, –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –ø–æ–¥–æ–±–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è. –ê–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞ –∫ –ø–æ–ª—É—á–µ–Ω–∏—é –ø–æ–¥–æ–±–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (—Å–º. –†–∏—Å—É–Ω–æ–∫ 22):

1. **SSE** ‚Äî —Ä–∞–≤–µ–Ω –≤–∞—Ä–∏–∞–Ω—Ç—É –∏–∑ SWA –∏ Snapshot Ensebles (–ø—Ä–∏–º–µ–Ω—è–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ LR –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, —á–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Ü–∏–∫–ª–∞);
2. **StarSSE** ‚Äî –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–≤–æ–π –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –∑–∞–ø—É—Å–∫ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ê–≤—Ç–æ—Ä—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—Ç –µ–≥–æ –∫–∞–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é SSE. –≠—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ö–æ–∂ —Å Model Soups.

![[Pasted image 20240408163612.png]]
–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –º–µ—Ç–æ–¥–∞ Model Soups –∏ –ø–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ:
![[Pasted image 20240408163631.png]]
–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è (StarSSE) –∏—Ç–æ–≥–æ–≤–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –¥–∞–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –∏ –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —É–ª—É—á—à–∞—é—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–æ—á–Ω–æ—Å—Ç—å.
- **Local DE soup** ‚Äî Model Soups –∏–∑ –º–æ–¥–µ–ª–µ–π, –æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (–ª–∏–Ω–µ–π–Ω–æ–≥–æ) —Å–ª–æ—è —Å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
- **Soup size** ‚Äî ****–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Å–æ–±–æ–π —Å –ø–æ–º–æ—â—å—é Uniform soup.

–ù–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö –º—ã –≤–∏–¥–∏–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –Ω–∏—Ö. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ —Ü–∏–∫–ª–∞–º–∏ –∏ –≤—ã—Å–æ–∫–∏–º LR –¥–∞—é—Ç –º–æ–¥–µ–ª–∏, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–µ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ –±–∞–∑–∏–Ω—ã **(semi-local).** –ò—Ö —Ç–æ—á–Ω–æ—Å—Ç—å —Ö—É–∂–µ —Ç–µ—Ö, –≥–¥–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –º–∞–ª–µ–Ω—å–∫–∏–µ **(local)** –∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ **(optimal)** –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LR.

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—É–Ω–∫—Ç—ã –≤ –ø–∞–π–ø–ª–∞–π–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Model Soups:

- –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OneCycle —Å –Ω–∞—á–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º LR –æ—Ç x2 –¥–æ x4 –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö –¥–æ 0.25 –æ—Ç –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞;
- Star-SSE –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ drop-in –∑–∞–º–µ–Ω—É SWA –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–∞—Ç—å –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã;
- –∞–≤—Ç–æ—Ä—ã –Ω–µ –≤–∞—Ä—å–∏—Ä–æ–≤–∞–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π, mixup-–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–º–µ—Å—Ç–µ —Å–æ Star-SSE –º–æ–∂–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç Model Soups.

### –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤—ã–≤–æ–¥—ã
–ò—Ç–∞–∫, –¥–∞–≤–∞–π—Ç–µ –∑–∞–∫—Ä–µ–ø–∏–º **—Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ —Ä–∞–∑–¥–µ–ª—É:**

1. –°–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–≤–æ–¥–∏—Ç –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞. –ò—Ö –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è —É—Å—Ä–µ–¥–Ω–∏—Ç—å.
2. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Å–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö Model Soups, –Ω—É–∂–Ω–∞ –æ–±—â–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è –∏–Ω—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
3. –≠—Ç–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ–±—É—á–µ–Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–∑–¥–µ—Å—å –≤—Å–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Å–µ—Ç–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞).
4. –ú–æ–¥–µ–ª–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ Model Soups, ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª–∏ –≤ –æ–¥–Ω–æ–π –±–∞–∑–∏–Ω–µ. –ü—Ä–∏ –ª–∏–Ω–µ–π–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –Ω–∏–º–∏ –Ω–µ –¥–æ–ª–∂–Ω–æ –≤–æ–∑–Ω–∏–∫–∞—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏ –≤–æ –≤—Å–µ—Ö —Ç–æ—á–∫–∞ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏.
5. SWA ‚Äî –∞–Ω–∞–ª–æ–≥ Model Soups, –Ω–æ —Å –¥—Ä—É–≥–∏–º –ø–æ–¥—Ö–æ–¥–æ–º –∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –±–∞–∑–∏–Ω—ã.
6. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OneCycle LR sheduler —Å –Ω–∞—á–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º LR –æ—Ç x2 –¥–æ x4 –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ, —Å–Ω–∏–∑–∏–≤ –ø—Ä–∏ —ç—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ –¥–æ 0.25 –æ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ).
7. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ StarSSE –≤–º–µ—Å—Ç–µ —Å –≤–∞—Ä–∏–∞—Ü–∏–µ–π –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –º–æ–∂–µ—Ç –±—ã—Ç—å –±–µ–π–∑–ª–∞–π–Ω–æ–º –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ Model Soups.

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Model Soups –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö
####  –£–ª—É—á—à–µ–Ω–∏–µ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–µ foundation models

–î–ª—è –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞ —Å —ç—Ç–æ–π –∑–∞–¥–∞—á–µ–π –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å –¥–≤–µ —Å—Ç–∞—Ç—å–∏: **‚Äú[Robust fine-tuning of zero-shot models](https://arxiv.org/abs/2109.01903)‚Äù** –∏ **‚Äú[Patching open-vocabulary models by interpolating weights](https://arxiv.org/abs/2208.05592)‚Äù**. –ú—ã –∫—Ä–∞—Ç–∫–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø–µ—Ä–≤—É—é –∏–∑ –Ω–∏—Ö.

**–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –º–µ—Ç–æ–¥–æ–≤**: –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ **—Ä–æ–±–∞—Å—Ç–Ω—É—é –º–æ–¥–µ–ª—å** –∑–∞ —Å—á–µ—Ç **—É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –Ω–∞—á–∞–ª—å–Ω–æ–π (zero-shot) –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ –º–æ–¥–µ–ª–∏**. –ü–æ—Å–∫–æ–ª—å–∫—É —É –º–æ–¥–µ–ª–∏ —É–∂–µ –µ—Å—Ç—å –Ω–µ–ø–ª–æ—Ö–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∏–∑ –∫–æ—Ä–æ–±–∫–∏, –∞ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –¥–≤–∏–≥–∞–µ—Ç –µ–µ –≤–µ—Å–∞ —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–º–∫–∞—Ö –±–∞–∑–∏–Ω—ã ‚Äî –º–µ–∂–¥—É —Ç–∞–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –µ—Å—Ç—å –ª–∏–Ω–µ–π–Ω–∞—è —Å–≤—è–∑—å. –î–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –∞–≤—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ–¥–æ–±–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –≤ –º–µ—Ç–æ–¥–µ **Robust fine-tuning of zero-shot models**.

–§–æ—Ä–º—É–ª–∏—Ä—É—é—Ç –æ–Ω–∏ –∑–∞–¥–∞—á—É —Ç–∞–∫: –ø—É—Å—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ in distribution –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤—ã—Å—Ç—É–ø–∞–µ—Ç ImageNet, –∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ distribution shift –¥–∞–Ω–Ω—ã—Ö (—Å–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–¥–≤–∏–≥–∞–º–∏ –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏) ‚Äî –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ Model Soups.

**–í–æ–ø—Ä–æ—Å**: ‚Äú–ú–æ–∂–µ—Ç –ª–∏ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –Ω–∞—á–∞–ª—å–Ω–æ–π –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–∞—Ç—å –Ω–∞–∏–ª—É—á—à—É—é —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –Ω–∞ distribution shift –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞ in distribution?‚Äù.

–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ **–ø–∞–π–ø–ª–∞–π–Ω–∞**:

1. –í –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –±–µ—Ä–µ—Ç—Å—è **CLIP.**
2. –ú–æ–¥–µ–ª—å —Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—Å—è –Ω–∞ **ImageNet** (–≤ end-to-end —Ä–µ–∂–∏–º–µ).
3. –° –ø–æ–º–æ—â—å—é –≤—ã—Ä–∞–∂–µ–Ω–∏—è $\mathcal{\theta_{a}} = (1-a) *\theta_{zero-shot} + a * \theta_{fine-tuned}$ –∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ $a$ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∏—Ç–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å.
4. –î–∞–ª–µ–µ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ in distribution –∏ distribution shift –¥–∞–Ω–Ω—ã—Ö.
![[Pasted image 20240408172255.png]]–û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ –≤—ã—à–µ:

- –æ—Ä–∞–Ω–∂–µ–≤—ã–π –∫—É–±–∏–∫ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π CLIP –º–æ–¥–µ–ª–∏ –≤ end-to-end —Ä–µ–∂–∏–º–µ;
- —Å–∏–Ω—è—è –ª–∏–Ω–∏—è ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å –≤—Å–µ–≤–æ–∑–º–æ–∂–Ω—ã—Ö supervised –º–æ–¥–µ–ª–µ–π –Ω–∞ ImageNet;
- —Ñ–∏–æ–ª–µ—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å –≤—Å–µ–≤–æ–∑–º–æ–∂–Ω—ã—Ö CLIP –º–æ–¥–µ–ª–µ–π, –≥–¥–µ –¥–æ–æ–±—É—á–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è;
- —Ä–æ–∑–æ–≤–∞—è –ª–∏–Ω–∏—è ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω–æ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–µ $a$.

–ú—ã –≤–∏–¥–∏–º: –¥–ª—è –≤—Å–µ–≤–æ–∑–º–æ–∂–Ω—ã—Ö CLIP –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ —Ç–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã—à–µ, –æ–¥–Ω–∞–∫–æ –Ω–∞—á–∞–ª—å–Ω–∞—è —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å –∫ distribution shift –Ω–∏–∂–µ –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å end-to-end –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º.

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã Model Soups –ø—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω–æ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–µ $a$**:

- –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö $a$ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å—Ç–µ—Ç –Ω–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö;
- –ø—Ä–∏ –∑–Ω–∞—á–µ–Ω–∏–∏ $a$, –±–ª–∏–∑–∫–æ–º –∫ —Å–µ—Ä–µ–¥–∏–Ω–µ, –ø–æ–ª—É—á–∞–µ—Ç—Å—è –Ω–∞–∏–ª—É—á—à–µ–µ distribution shift –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ–º in distibution.

#### –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≥–∏–±–∫–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –ø–æ–≤–µ–¥–µ–Ω–∏–µ LLM –ø–æ—Å–ª–µ —Å—Ç–∞–¥–∏–∏ RLHF

–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π **–ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è LLM** –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –¥–≤–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ç–∞–¥–∏–∏:

1. –ù–∞—á–∞–ª—å–Ω—É—é –ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.
2. –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é RL –≤ –∑–∞–¥–∞—á–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.

–ù–∞ –≤—Ç–æ—Ä–æ–º —à–∞–≥–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å: —á–µ–º –ª—É—á—à–µ –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º, —Ç–µ–º –±–æ–ª—å—à–µ –∏—Ç–æ–≥–æ–≤–∞—è –Ω–∞–≥—Ä–∞–¥–∞. **–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å:** —ç—Ç–∞ —Å—Ç–∞–¥–∏—è ‚Äú–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è‚Äù –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ –∫ –Ω–∞—à–µ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é –æ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, —Ç—Ä–µ–±—É–µ—Ç –æ—á–µ–Ω—å –º–∞—Å—à—Ç–∞–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ —É—á–µ—Ç–∞ –≤ –Ω–∏—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤.

–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∞—è **–ø—Ä–æ–±–ª–µ–º–∞**: –µ—Å–ª–∏ –Ω–∞ —Å—Ç–∞–¥–∏–∏ RLHF –º—ã –Ω–µ —É—á–ª–∏ —á—Ç–æ-—Ç–æ –≤ —Ä–∞–º–∫–∞—Ö —Ñ—É–Ω–∫—Ü–∏–∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è ‚Äî –¥–ª—è —á–∞—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –µ–µ –æ—Ç–≤–µ—Ç—ã –Ω–µ –±—É–¥—É—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏. –î–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±–æ–ª–µ–µ –≥–∏–±–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä—ã **‚Äú[Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging](https://arxiv.org/abs/2310.11564)‚Äù** –ø—Ä–∏–¥—É–º–∞–ª–∏ —Å–≤–æ–π –ø–æ–¥—Ö–æ–¥: –∑–∞ —Å—á–µ—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Model Soups –º—ã —Ä–µ—à–∞–µ–º –∑–∞–¥–∞—á—É –±–æ–ª–µ–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –°—Ö–µ–º–∞—Ç–∏—á–Ω–æ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:

![[Pasted image 20240408172944.png]]
**–ò–¥–µ—è –º–µ—Ç–æ–¥–∞:**

1. –°–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ–º –ø—Ä–æ—Ü–µ–¥—É—Ä—É RLHF, —Ñ–æ—Ä–º—É–ª–∏—Ä—É—è Reward —Ç–∞–∫, —á—Ç–æ–±—ã –∏—Ç–æ–≥–æ–≤–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è–ª–æ —Å—Ä–µ–¥–Ω–µ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞ –ø–ª–∞–Ω–µ—Ç–µ, –ø–æ–ª—É—á–∞–µ–º General –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏.
2. –î–∞–ª–µ–µ –ø–æ–¥ –∫–∞–∂–¥—ã–π –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–π –Ω–∞—Å –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ–º –æ—Å–æ–±—ã–π Reward –∏ —Ç–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ (–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) –≤–µ—Å–∞.
3. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —É—Å—Ä–µ–¥–Ω—è–µ–º –≤–µ—Å–∞ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ General, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–∏ —ç—Ç–æ–º –≤–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–∫–ª–∞–¥–∞ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏.

–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º—ã –ø–æ–ª—É—á–∞–µ–º —É–¥–æ–±–Ω–æ–µ Post-hoc —Ä–µ—à–µ–Ω–∏–µ, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –º–æ–∂–µ–º —Ä–∞—Å—à–∏—Ä—è—Ç—å –±–∞–∑—É –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ –∏ –¥–æ–±–∞–≤–ª—è—Ç—å –±–æ–ª—å—à–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –ø–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

#### –ê–¥–∞–ø—Ç–∞—Ü–∏—è LLM –ø–æ–¥ –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è

–°–µ–≥–æ–¥–Ω—è –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ LLM –∏ –¥—Ä—É–≥–∏—Ö –≥–∏–≥–∞–Ω—Ç—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –∑–∞–¥–∞—á—É –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **LoRA** –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à–æ–π –¥–æ–±–∞–≤–∫–∏ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏.

–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ LoRA –Ω–µ —Å–¥–≤–∏–≥–∞–µ—Ç –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ: –æ–Ω–∏ –æ—Å—Ç–∞—é—Ç—Å—è –≤ —Ç–æ–π –±–∞–∑–∏–Ω–µ, –≥–¥–µ –º–æ–¥–µ–ª—å —Å–æ—à–ª–∞—Å—å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –º–Ω–æ–≥–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö LoRA ‚Äî –≤—ã—É—á–µ–Ω–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏ –∫ –≤–µ—Å–∞–º –º–æ–∂–Ω–æ –±—É–¥–µ—Ç —É—Å—Ä–µ–¥–Ω–∏—Ç—å –∏ –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –ª—É—á—à–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏.

–í–∞–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å: —Ä–µ—á—å –∏–¥–µ—Ç –∏–º–µ–Ω–Ω–æ –ø—Ä–æ zero-shot —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏, –≤–µ–¥—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ ‚Äú–∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç‚Äù –≤–Ω—É—Ç—Ä–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ ‚Äî –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø–æ–¥–æ–±–Ω–æ–π –∑–∞–¥–∞—á–∏. –û–¥–Ω–∞–∫–æ –æ–Ω–æ —Ç—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ü–æ–¥–æ–±–Ω–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞ —Ä–∞–±–æ—Ç—ã —Å–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ —Ä–∞–±–æ—Ç–µ **‚Äú[LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition](https://arxiv.org/abs/2307.13269)‚Äù.**

–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–æ–≤—É—é –ø–∞—Ä–∞–¥–∏–≥–º—É –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ LLM –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è:

![[Pasted image 20240408173407.png]]–ê–≤—Ç–æ—Ä—ã —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç **–Ω–∞—á–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è**:

1. –ï—Å—Ç—å –∑–∞—Ä–∞–Ω–µ–µ –≤—ã–±—Ä–∞–Ω–Ω–∞—è **LLM** –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏;
2. –ï—Å—Ç—å —Ö–∞–± —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö **LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –ø–æ–¥ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã;
3. –ï—Å—Ç—å –Ω–∞–±–æ—Ä **–ø–∞—Ä ‚Äú–∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç‚Äù** –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ –º–æ–¥–µ–ª–∏.

**–ó–∞–¥–∞—á–∞**: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏.

**–ê–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—à–µ–Ω–∏—è:**

1. –°–æ–∑–¥–∞–¥–∏–º –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –ø–æ–¥ –∫–∞–∂–¥—ã–π –∏–∑ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤;
2. –£—Å—Ä–µ–¥–Ω–∏–º –≤—Å–µ –∞–¥–∞–ø—Ç–µ—Ä—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–æ–≤—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Model Soups);
3. –î–æ–±–∞–≤–∏–º –ø–æ–ª—É—á–µ–Ω–Ω—É—é –¥–æ–±–∞–≤–∫—É –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏;
4. –û—Ü–µ–Ω–∏–º –æ—à–∏–±–∫—É –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Ç–µ–∫—É—â–∏—Ö –≤–µ—Å–∞—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞.

![[Pasted image 20240408173517.png]]
–ó–∞—Ç–µ–º –º—ã –ø–æ–≤—Ç–æ—Ä—è–µ–º –≤—Å–µ —à–∞–≥–∏ –∏ –∏–∑–º–µ–Ω—è–µ–º –ø—Ä–∏ —ç—Ç–æ–º –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å –Ω–∞–∏–º–µ–Ω—å—à–µ–π –æ—à–∏–±–∫–∏ –Ω–∞ –∏–º–µ—é—â–∏—Ö—Å—è —É –Ω–∞—Å –ø—Ä–∏–º–µ—Ä–∞—Ö. –ü—Ä–æ—Ü–µ—Å—Å –ø–æ—Ö–æ–∂ –Ω–∞ Learned Soup (–æ –Ω–µ–º –º—ã —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∏ –≤ –ø–µ—Ä–≤–æ–º —Ä–∞–∑–¥–µ–ª–µ), –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –Ω–µ–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ¬†–º–µ—Ç–æ–¥–∞ ([https://facebookresearch.github.io/nevergrad/](https://facebookresearch.github.io/nevergrad/)).

#### –£–ª—É—á—à–µ–Ω–∏–µ –¥–æ–º–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
–ò–¥–µ—è –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ä–∞–∑—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –¥–æ–º–µ–Ω–∞–º–∏, –Ω–µ –Ω–æ–≤–∞: –≤ —ç—Ç–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∫–∞–∂–¥—ã–π –≥–æ–¥ –ø–æ—è–≤–ª—è—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã. –í —Å—Ç–∞—Ç—å–µ ‚Äú[A Re-Parameterized Vision Transformer (ReVT) for Domain-Generalized Semantic Segmentation](https://arxiv.org/abs/2308.13331)‚Äù –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø–æ–¥—Ö–æ–¥, –≥–¥–µ Model Soups –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—é—â–µ–π —Å—Ä–∞–∑—É –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

![[Pasted image 20240408173631.png]]
**–ò–¥–µ—è –º–µ—Ç–æ–¥–∞:** –ø—É—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–∞–±–æ—Ä —Ü–µ–ª–µ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –±—ã —Ö–æ—Ç–µ–ª–∏ –≤–∏–¥–µ—Ç—å –º–æ–¥–µ–ª—å —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º. –í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –Ω–∞—á–∞–ª—å–Ω—ã–π –∏ —Ü–µ–ª–µ–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç—ã –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –æ–¥–Ω–æ–º—É –±–æ–ª—å—à–æ–º—É –¥–æ–º–µ–Ω—É. **–ó–∞–¥–∞—á–∞** —Å–≤–æ–¥–∏—Ç—Å—è –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é —Ç–∞–∫–æ–≥–æ –º–µ—Ç–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–∞—á–∞–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –∫–∞—á–µ—Å—Ç–≤–æ –±—É–¥–µ—Ç —Ä–∞—Å—Ç–∏ –∏ –Ω–∞ —Ü–µ–ª–µ–≤–æ–º –Ω–∞–±–æ—Ä–µ. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ —Å–≤–æ–π **–¥–∏–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:**

- –≤—ã–±–∏—Ä–∞–µ–º —Å–µ—Ç—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö –∞–≤—Ç–æ—Ä–æ–≤ —ç—Ç–æ **Segformer B2, B3, B5**);
- –±–µ—Ä–µ–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö **—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç GTA5** –¥–ª—è –∑–∞–¥–∞—á–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –¥–æ–º–µ–Ω–µ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –º–∞—à–∏–Ω;
- –±–µ—Ä–µ–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ **Cityscapes Mapillary Vistas, BDD100k, ACDC, KITTI** –∏–∑ —Ç–æ–≥–æ –∂–µ –æ–±—â–µ–≥–æ –¥–æ–º–µ–Ω–∞.

**–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é:**

1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–Ω–∫–æ–¥–µ—Ä –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏, –ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –Ω–∞ ImageNet.
2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ–∫–æ–¥–µ—Ä —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º.
3. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –ø–æ–¥ –∫–∞–∂–¥—É—é –æ—Ç–¥–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å.

**–ü–∞–π–ø–ª–∞–π–Ω –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π** –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:
![[Pasted image 20240408173756.png]]
–§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–∞—é—Ç —Ä–∞–∑–Ω—ã–π –ø–æ —Å–∏–ª–µ **–Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π:**

- **–±–∞–∑–æ–≤—ã–µ** ‚Äî Resize, Random Crop, Flip;
- **—É—Å–∏–ª–µ–Ω–Ω—ã–µ** ‚Äî PhotoAug, Bilateral Filter;
- **–Ω–∞–∏–±–æ–ª–µ–µ —Å–∏–ª—å–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è** ‚Äî PixMix.

–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –æ–±—É—á–µ–Ω–∏—è –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ Supplementary Material, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–º –ø–æ—Å–ª–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ —Å—Ç–∞—Ç—å–µ –Ω–∞ [arxiv.](https://arxiv.org/abs/2308.13331)

**–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è** —Å–ª–µ–¥—É—é—â–∏–π:

1. –í—ã–±–∏—Ä–∞–µ–º —Ç—Ä–∏ –º–æ–¥–µ–ª–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—é—Ç –Ω–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ;
2. –£—Å—Ä–µ–¥–Ω—è–µ–º –∏—Ö;
3. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–µ–∫–æ–¥–µ—Ä–∞ –≤—ã–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω –∏–∑ –∏–º–µ—é—â–∏—Ö—Å—è —Å–æ–≥–ª–∞—Å–Ω–æ –º–µ—Ç—Ä–∏–∫–∞–º.

#### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø—Ä—É–Ω–∏–Ω–≥–µ
–í —Ä–∞–º–∫–∞—Ö —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ Model Soups –∏—Å–ø–æ–ª—å–∑—É—é—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–ø–∞—Ä—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –í —Å—Ç–∞—Ç—å–µ ‚Äú[Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging](https://arxiv.org/abs/2306.16788)‚Äù –∞–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä—É–Ω–∏–Ω–≥–∞. –ö—Å—Ç–∞—Ç–∏, –æ –ø—Ä—É–Ω–∏–Ω–≥–µ –º—ã –ø–∏—Å–∞–ª–∏ –≤ –æ–¥–Ω–æ–π –∏–∑ –Ω–∞—à–∏—Ö [—Å—Ç–∞—Ç–µ–π](/e5776c9b167b4ce8af4298a0d4db2497?pvs=25) üòä

–î–ª—è –ø—Ä—É–Ω–∏–Ω–≥–∞ –∞–≤—Ç–æ—Ä—ã –ø—Ä–∏–º–µ–Ω–∏–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º **Iterative Magnitude Pruning (IMP)**. –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤:

1. –ù–∞—á–∏–Ω–∞–µ–º —Å —Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏;
2. –î–ª—è –≤—Å–µ—Ö –≤–µ—Å–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∏–∑ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö / –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤ –≤—ã—á–∏—Å–ª—è–µ–º L1 –Ω–æ—Ä–º—É;
3. –ó–∞–Ω—É–ª—è–µ–º –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã–π % –Ω–∞–∏–º–µ–Ω—å—à–∏—Ö –ø–æ L1 –Ω–æ—Ä–º–µ –≤–µ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ —Å–ª–æ–µ–≤;
4. –ü–µ—Ä–µ–æ–±—É–≤–∞–µ–º —Å–µ—Ç—å.

–í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å –≤–∏–∑—É–∞–ª—å–Ω–æ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:
![[Pasted image 20240408174335.png]]
–ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ –≤–∏–¥–µ Model Soups ‚Äî –æ–Ω–æ –ø–æ–∑–≤–æ–ª–∏–ª–æ —É–ª—É—á—à–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä—É–Ω–∏–Ω–≥–∞. –ò–¥–µ—è —Å–ª–µ–¥—É—é—â–∞—è: –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –Ω–µ –æ–¥–Ω–æ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, –∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö, —Å—Ç–∞—Ä—Ç—É—é—â–∏—Ö –æ—Ç –µ–¥–∏–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ —Å —Ä–∞–∑–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å Model Soups. –ü–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é –æ–±—É—á–µ–Ω–∏—è –≤–µ—Å–∞ –º–æ–¥–µ–ª–µ–π —É—Å—Ä–µ–¥–Ω—è—é—Ç—Å—è.
![[Pasted image 20240408174409.png]]

# KAN: Kolmogorov‚ÄìArnold Networks

While MLPs have fixed activation functions on nodes (‚Äúneurons‚Äù), KANs have learnable activation functions on edges (‚Äúweights‚Äù). **KANs have no linear weights at all ‚Äì every weight parameter is replaced by a univariate function parametrized as a spline.**

y. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users.
![[Pasted image 20240502142437.png]]
## Kolmogorov-Arnold Representation theorem
Vladimir Arnold and Andrey Kolmogorov established that if f is a multivariate continuous function on a bounded domain, then f can be written as a finite composition of continuous functions of a single variable and the binary operation of addition.

Eq. (2.1):
![[Pasted image 20240502143851.png]]
In a sense, they showed that the only true multivariate function is addition, since every other function can be written using univariate functions and sum. One might naively consider this great news for machine learning: learning a high-dimensional function boils down to learning a polynomial number of 1D functions. However, these 1D functions can be non-smooth and even fractal, so they may not be learnable in practice.

However, we are more optimistic about the usefulness of the Kolmogorov-Arnold theorem for machine learning. First of all, we need not stick to the **original  which has only two-layer nonlinearities and a small number of terms (2n + 1) in the hidden layer**: we will generalize the network to arbitrary widths and depths. Secondly, most functions in science and daily life are often smooth and have sparse compositional structures, potentially facilitating smooth Kolmogorov-Arnold representations. **The philosophy here is close to the mindset of physicists, who often care more about typical cases rather than worst cases. After all, our physical world and machine learning tasks must have structures to make physics and machine learning useful or generalizable at all**
## KAN architecture 

Suppose we have a supervised learning task consisting of input-output pairs {xi , yi}, where we want to find f such that yi ‚âà f(xi) for all data points. Eq. (2.1) implies that we are done if we can find appropriate univariate functions œï_q,p and Œ¶_q. This inspires us to design a neural network which explicitly parametrizes Eq. (2.1).

**Since all functions to be learned are univariate functions, we can parametrize each 1D function as a B-spline curve, with learnable coefficients of local B-spline basis functions**
Now we have a prototype of KAN, whose computation graph is exactly specified by Eq. (2.1)  with the input dimension n = 2, appearing as a two-layer neural network with activation functions placed on edges instead of nodes (simple summation is performed on nodes), and with width 2n + 1 in the middle layer.
The breakthrough occurs when we notice the analogy between MLPs and KANs. In MLPs, once we define a layer (which is composed of a linear transformation and nonlinearties), we can stack more layers to make the network deeper. To build deep KANs, we should first answer: ‚Äúwhat is a KAN layer?‚Äù It turns out that a KAN layer with nin-dimensional inputs and nout-dimensional outputs can be defined as a matrix of 1D functions
![[Pasted image 20240502150139.png]]
**Implementation details**
![[Pasted image 20240502152925.png]]![[Pasted image 20240502153054.png]]
Then there are in total O(N^2L(G + k)) ‚àº O(N^2LG) parameters. In contrast, an MLP with depth L and width N only needs O(N^2L) parameters, which appears to be more efficient than KAN. Fortunately, KANs usually require much smaller N than MLPs, which not only saves parameters, but also achieves better generalization and facilitates interpretability. 




# Self-supervised learning

–ù–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è 3 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–∞:

- **–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞ (pretext task)** ‚Äî —Å–∞–º–∞ –∑–∞–¥–∞—á–∞ SSL —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π. –ò–º–µ–Ω–Ω–æ –µ–µ —Ä–µ—à–∞–µ—Ç –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –Ω–∞—É—á–∏—Ç—å—Å—è –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö;
- **–ø—Å–µ–≤–¥–æ-—Ä–∞–∑–º–µ—Ç–∫–∞** ‚Äî —Ç–∞ —Å–∞–º–∞—è –¥–µ—à–µ–≤–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞, –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–∞—è –±–µ–∑ —É—á–∞—Å—Ç–∏—è —á–µ–ª–æ–≤–µ–∫–∞;
- **–ø–æ—Å–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞ (downstream task)** ‚Äî –∑–∞–¥–∞—á–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–≤–µ—Ä—è—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ –≤—ã—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, —ç—Ç–æ –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ (KNN, LinReg, LogReg –∏ –¥—Ä—É–≥–∏–µ), –æ–±—É—á–∞—é—â–∏–µ—Å—è –Ω–∞ –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö —Å –ø–æ–º–æ—â—å—é SSL-–º–æ–¥–µ–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö. –ò–Ω–æ–≥–¥–∞ –±—ã–≤–∞–µ—Ç –∏ —Ç–∞–∫, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è –∏ –¥–æ–æ–±—É—á–∞–µ—Ç—Å—è —Ü–µ–ª–∏–∫–æ–º.
![[Pasted image 20240506144015.png]]
**–í–∏–¥—ã –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á**:
–í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö SOTA-–º–µ—Ç–æ–¥–∞—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Å–µ–≤–¥–æ-—Ä–∞–∑–º–µ—Ç–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–≤–æ–¥–∏—Ç—Å—è –∫ –¥–≤—É–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º:
1. Multi-view invariance: –∑–¥–µ—Å—å –ø—Å–µ–≤–¥–æ-—Ä–∞–∑–º–µ—Ç–∫–∞ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É contrastive learning, —Ç–æ –µ—Å—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ —è–≤–ª—è—é—Ç—Å—è –¥–≤–∞ –ø–æ-—Ä–∞–∑–Ω–æ–º—É –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º–∏ ‚Äî –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥—Ä—É–≥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. ![[Pasted image 20240506144130.png]]
2. –ó–∞–¥–∞—á–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–¥–∞–ª—è—é—Ç—Å—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–∞—Ç—á–∏, –∞ —Å–µ—Ç—å —É—á–∏—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –ø—Å–µ–≤–¥–æ-—Ä–∞–∑–º–µ—Ç–∫–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –ø–∞—Ä (X, Y), –≥–¥–µ Y ‚Äî –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∞ –• ‚Äî –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º —É–¥–∞–ª–µ–Ω–∞ —á–∞—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. ![[Pasted image 20240506144154.png]]
**–í—ã–¥–µ–ª—è—é—Ç —á–µ—Ç—ã—Ä–µ –±–æ–ª—å—à–∏—Ö —Å–µ–º–µ–π—Å—Ç–≤–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ SSL:**
1. –ú–µ—Ç–æ–¥—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ metric learning;
2. –ú–µ—Ç–æ–¥—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ self-distillation;
3. –ú–µ—Ç–æ–¥—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ [–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ](https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D0%BD%D0%BE%D0%BD%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BE%D1%80%D1%80%D0%B5%D0%BB%D1%8F%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7);
4. –ú–µ—Ç–æ–¥—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

## Masked Autoencoders: A PyTorch Implementation

**Masking**¬†Following ViT, an image is divided into regular non-overlapping patches. Then a subset of  
patches is sampled and the remaining ones are masked.

**MAE encoder**¬†The encoder is a ViT but applied only on visible, unmasked patches. Thus the encoder only operates on a small subset (~25%) of the full et. Masked patches are removed, no mask tokens are used. This allows is to train very large encoders with only a fraction of compute and memory. The full set is handled by a lightweight decoder.

**MAE decoder**¬†The input to the MAE decoder is the full set of tokens consisting of (i) encoded visible patches, and (ii) mask tokens. Each mask token is a shared, learned vector that indicates the presence of a missing patch to be predicted. Positional embeddings are added to all tokens in this full set; without this, mask tokens would have no information about their location in the image. The decoder has another series of Transformer blocks. The MAE decoder is only used during pre-training to perform the image reconstruction task. Therefore, the decoder architecture can be flexibly designed in a manner that is independent of the encoder design.

**Reconstruction Target**¬†MAE reconstructs the input by predicting the pixel values for each masked patch. Each element in the decoder‚Äôs output is a vector of pixel values representing a patch. The last layer of the decoder is a linear projection whose number of output channels equals the number of pixel values in a patch. The decoder‚Äôs output is reshaped to form a reconstructed image. The loss function computes the mean squared error (MSE) between the reconstructed and original images in the pixel space. Loss is computed only on masked patches, similar to BERT.

# MoE (mixture of experts) models

## What's MoE?
¬†In the context of transformer models, a MoE consists of two main elements:
- **Sparse MoE layers**¬†are used instead of dense feed-forward network (FFN) layers. MoE layers have a certain number of ‚Äúexperts‚Äù (e.g. 8), where each expert is a neural network. In practice, the experts are FFNs, but they can also be more complex networks or even a MoE itself, leading to hierarchical MoEs!
- A¬†**gate network or router**, that determines which tokens are sent to which expert. For example, in the image below, the token ‚ÄúMore‚Äù is sent to the second expert, and the token "Parameters‚Äù is sent to the first network. As we‚Äôll explore later, we can send a token to more than one expert. How to route a token to an expert is one of the big decisions when working with MoEs - the router is composed of learned parameters and is pretrained at the same time as the rest of the network.

Although MoEs provide benefits like efficient pretraining and faster inference compared to dense models, they also come with challenges:

- **Training:**¬†MoEs enable significantly more compute-efficient pretraining, but they‚Äôve historically struggled to generalize during fine-tuning, leading to overfitting.
- **Inference:**¬†Although a MoE might have many parameters, only some of them are used during inference. This leads to much faster inference compared to a dense model with the same number of parameters. However, all parameters need to be loaded in RAM, so memory requirements are high. For example, given a MoE like Mixtral 8x7B, we‚Äôll need to have enough VRAM to hold a dense 47B parameter model. Why 47B parameters and not 8 x 7B = 56B? That‚Äôs because in MoE models, only the FFN layers are treated as individual experts, and the rest of the model parameters are shared. At the same time, assuming just two experts are being used per token, the inference speed (FLOPs) is like using a 12B model (as opposed to a 14B model), because it computes 2x7B matrix multiplications, but with some layers shared (more on this soon).

## What's Sparsity?

Let‚Äôs dive deeper into Shazeer's exploration of MoEs for translation. The idea of conditional computation (parts of the network are active on a per-example basis) allows one to scale the size of the model without increasing the computation, and hence, this led to thousands of experts being used in each MoE layer.

This setup introduces some challenges. For example, although large batch sizes are usually better for performance, batch sizes in MOEs are effectively reduced as data flows through the active experts. For example, if our batched input consists of 10 tokens,¬†**five tokens might end in one expert, and the other five tokens might end in five different experts, leading to uneven batch sizes and underutilization**.

How can we solve this? A learned gating network (G) decides which experts (E) to send a part of the input:
![[Pasted image 20240515163618.png]]

In this setup, all experts are run for all inputs - it‚Äôs a weighted multiplication. But, what happens if G is 0? If that‚Äôs the case, there‚Äôs no need to compute the respective expert operations and hence we save compute. What‚Äôs a typical gating function? In the most traditional setup, we just use a simple network with a softmax function. The network will learn which expert to send the input.
![[Pasted image 20240515163627.png]]


Shazeer‚Äôs work also explored other gating mechanisms, such as Noisy Top-k Gating. This gating approach introduces some (tunable) noise and then keeps the top k values. That is:
![[Pasted image 20240515163725.png]]
This sparsity introduces some interesting properties. By using a low enough k (e.g. one or two), we can train and run inference much faster than if many experts were activated. Why not just select the top expert? The initial conjecture was that routing to more than one expert was needed to have the gate learn how to route to different experts, so at least two experts had to be picked

Why do we add noise? That‚Äôs for load balancing!

## Load balancing with MoEs

As discussed before, if all our tokens are sent to just a few popular experts, that will make training inefficient. In a normal MoE training, the gating network converges to mostly activate the same few experts. This self-reinforces as favored experts are trained quicker and hence selected more. To mitigate this, an¬†**auxiliary loss**¬†is added to encourage giving all experts equal importance. This loss ensures that all experts receive a roughly equal number of training examples.

ransformers are a very clear case that scaling up the number of parameters improves the performance, so it‚Äôs not surprising that Google explored this with¬†[GShard](https://arxiv.org/abs/2006.16668), which explores scaling up transformers beyond 600 billion parameters.

GShard replaces every other FFN layer with an MoE layer using top-2 gating in both the encoder and the decoder. The next image shows how this looks like for the encoder part. This setup is quite beneficial for large-scale computing: when we scale to multiple devices, the MoE layer is shared across devices while all the other layers are replicated
![[Pasted image 20240515164158.png]]
- **Random routing**: in a top-2 setup, we always pick the top expert, but the second expert is picked with probability proportional to its weight.
- **Expert capacity**: we can set a threshold of how many tokens can be processed by one expert. If both experts are at capacity, the token is considered overflowed, and it‚Äôs sent to the next layer via residual connections (or dropped entirely in other projects)

## Switch transformers

The Switch Transformers paper proposes a Switch Transformer layer that receives two inputs (two different tokens) and has four experts.
Contrary to the initial idea of using at least two experts, Switch Transformers uses a simplified single-expert strategy. The effects of this approach are:
- The router computation is reduced
- The batch size of each expert can be at least halved
- Communication costs are reduced
- Quality is preserved

Switch Transformers also explores the concept of expert capacity: **expert capacity = (tokens_per_batch/number_of_experts) * capacity_factor**

Switch Transformer authors also revisit and simplify the load balancing loss mentioned in the sections.** For each Switch layer, the auxiliary loss is added to the total model loss during training. This loss encourages uniform routing and can be weighted using a hyperparameter.**

Switch Transformers uses an encoder-decoder setup in which they did a MoE counterpart of T5. The¬†[GLaM](https://arxiv.org/abs/2112.06905)¬†paper explores pushing up the scale of these models by training a model matching GPT-3 quality using 1/3 of the energy (yes, thanks to the lower amount of computing needed to train a MoE, they can reduce the carbon footprint by up to an order of magnitude). The authors focused on decoder-only models and few-shot and one-shot evaluation rather than fine-tuning. They used Top-2 routing and much larger capacity factors. In addition, they explored the capacity factor as a metric one can change during training and evaluation depending on how much computing one wants to use.

## Stabilizing training with router Z-loss
The balancing loss previously discussed can lead to instability issues. We can use many methods to stabilize sparse models at the expense of quality. For example, introducing dropout improves stability but leads to loss of model quality. On the other hand, adding more multiplicative components improves quality but decreases stability.

Router z-loss, introduced in¬†[ST-MoE](https://arxiv.org/abs/2202.08906), significantly improves training stability without quality degradation by penalizing large logits entering the gating network. Since this loss encourages absolute magnitude of values to be smaller, roundoff errors are reduced, which can be quite impactful for exponential functions such as the gating. We recommend reviewing the paper for details.

## What does an expert learn?

The ST-MoE authors observed that encoder experts specialize in a group of tokens or shallow concepts. For example, we might end with a punctuation expert, a proper noun expert, etc. On the other hand, the decoder experts have less specialization. The authors also trained in a multilingual setup. Although one could imagine each expert specializing in a language, the opposite happens: due to token routing and load balancing, there is no single expert specialized in any given language.
## How does scaling the number of experts impact pretraining?

More experts lead to improved sample efficiency and faster speedup, but these are diminishing gains (especially after 256 or 512), and more VRAM will be needed for inference. The properties studied in Switch Transformers at large scale were consistent at small scale, even with 2, 4, or 8 experts per layer.
## Fine-tuning MoEs

The overfitting dynamics are very different between dense and sparse models. Sparse models are more prone to overfitting, so we can explore higher regularization (e.g. dropout) within the experts themselves (e.g. we can have one dropout rate for the dense layers and another, higher, dropout for the sparse layers).

One question is whether to use the auxiliary loss for fine-tuning. The ST-MoE authors experimented with turning off the auxiliary loss, and the quality was not significantly impacted, even when up to 11% of the tokens were dropped. Token dropping might be a form of regularization that helps prevent overfitting.

Switch Transformers observed that at a fixed pretrain perplexity, the sparse model does worse than the dense counterpart in downstream tasks, especially on reasoning-heavy tasks such as SuperGLUE. On the other hand, for knowledge-heavy tasks such as TriviaQA, the sparse model performs disproportionately well. The authors also observed that a fewer number of experts helped at fine-tuning. Another observation that confirmed the generalization issue is that the model did worse in smaller tasks but did well in larger tasks.

One could experiment with freezing all non-expert weights. That is, we'll only update the MoE layers. This leads to a huge performance drop. We could try the opposite: freezing only the parameters in MoE layers, which worked almost as well as updating all parameters. This can help speed up and reduce memory for fine-tuning. This can be somewhat counter-intuitive as 80% of the parameters are in the MoE layers (in the ST-MoE project). Their hypothesis for that architecture is that, as expert layers only occur every 1/4 layers, and each token sees at most two experts per layer, updating the MoE parameters affects much fewer layers than updating other parameters.

One last part to consider when fine-tuning sparse MoEs is that they have different fine-tuning hyperparameter setups - e.g., sparse models tend to benefit more from smaller batch sizes and higher learning rates

MoEs benefit more from a higher number of tasks. Unlike the previous discussion suggesting to turn off the auxiliary loss function, the loss actually prevents overfitting.

## When to use Sparse MoEs vs Dense models?

Experts are useful for high throughput scenarios with many machines. Given a fixed compute budget for pretraining, a sparse model will be more optimal. For low throughput scenarios with little VRAM, a dense model will be better.

**Note:**¬†one cannot directly compare the number of parameters between sparse and dense models, as both represent significantly different things.

## Making MoEs go brrrrrr

###  Parallelism
Let‚Äôs do a brief review of parallelism:

- **Data parallelism:**¬†the same weights are replicated across all cores, and the data is partitioned across cores.
- **Model parallelism:**¬†the model is partitioned across cores, and the data is replicated across cores.
- **Model and data parallelism:**¬†we can partition the model and the data across cores. Note that different cores process different batches of data.
- **Expert parallelism**: experts are placed on different workers. If combined with data parallelism, each core has a different expert and the data is partitioned across all cores

With expert parallelism, experts are placed on different workers, and each worker takes a different batch of training samples. For non-MoE layers, expert parallelism behaves the same as data parallelism. For MoE layers, tokens in the sequence are sent to workers where the desired experts reside.

### Capacity Factor and communication costs
Increasing the capacity factor (CF) increases the quality but increases communication costs and memory of activations. If all-to-all communications are slow, using a smaller capacity factor is better. A good starting point is using top-2 routing with 1.25 capacity factor and having one expert per core. During evaluation, the capacity factor can be changed to reduce compute.

### Serving techniques

A big downside of MoEs is the large number of parameters. For local use cases, one might want to use a smaller model. Let's quickly discuss a few techniques that can help with serving:

- The Switch Transformers authors did early distillation experiments. By distilling a MoE back to its dense counterpart, they could keep 30-40% of the sparsity gains. Distillation, hence, provides the benefits of faster pretaining and using a smaller model in production.
- Recent approaches modify the routing to route full sentences or tasks to an expert, permitting extracting sub-networks for serving.
- Aggregation of Experts (MoE): this technique merges the weights of the experts, hence reducing the number of parameters at inference time.

### More on efficient training



## PyTorch implementation

### Understanding attention intuition

![[Pasted image 20240516080205.png]]To ensure the integrity of the autoregressive language generation process, particularly in a decoder-only model, the code implements masking. This masking technique is crucial as it obscures any information following the current token's position, thereby directing the model's attention to only the preceding parts of the sequence. Such an attention mechanism is known as causal self-attention.

Let's see how single head performs computation:
```python
torch.manual_seed(1337)
B,T,C = 4,8,32 # batch, time, channels
x = torch.randn(B,T,C)

# let's see a single Head perform self-attention
head_size = 16
key = nn.Linear(C, head_size, bias=False)
query = nn.Linear(C, head_size, bias=False)
value = nn.Linear(C, head_size, bias=False)
k = key(x)   # (B, T, 16)
q = query(x) # (B, T, 16)
wei =  q @ k.transpose(-2, -1) C**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T)

tril = torch.tril(torch.ones(T, T))
#wei = torch.zeros((T,T))
wei = wei.masked_fill(tril == 0, float('-inf'))
wei = F.softmax(wei, dim=-1) #B,T,T
wei = nn.Dropout(wei)

v = value(x) #B,T,H
out = wei @ v # (B,T,T) @ (B,T,H) -> (B,T,H)
out.shape
```
Multi-head self attention applies multiple attention heads in parallel, each focusing on a separate section of the channel (the embedding dimension). Multi-head self attention essentially improves the learning process and improves efficiency of model training due to the inherently parallel implementation
To make this multi-headed we create a Module of heads and apply them in parallel:
```
heads= nn.ModuleList([Head(head_size) for _ in range(num_heads)])
out = torch.cat([h(x) for h in self.heads],dim=-1)
```

### Creating an expert module

In the Sparse Mixture of Experts (MoE) architecture, the self-attention mechanism within each transformer block remains unchanged. However, a notable alteration occurs in the structure of each block: **the standard feed-forward neural network is replaced with several sparsely activated feed-forward networks, known as experts.**

"Sparse activation" refers to the process where each token in the sequence is routed to only a limited number of these experts ‚Äì typically one or two ‚Äì out of the total pool available.
```python
class Expert(nn.Module):
    """ An MLP is a simple linear layer followed by a non-linearity i.e. each Expert """

    def __init__(self, n_embd):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(n_embd, 4 * n_embd),
            nn.ReLU(),
            nn.Linear(4 * n_embd, n_embd),
            nn.Dropout(dropout),
        )

    def forward(self, x):
        return self.net(x)
```
### Top-k gating  intuition

![[Pasted image 20240516081259.png]]

```python
#Understanding how gating works
num_experts = 4
top_k=2
n_embed=32

mh_output = torch.randn(2, 4, n_embed)

topkgate_linear = nn.Linear(n_embed, num_experts) # nn.Linear(32, 4)

logits = topkgate_linear(mh_output)
top_k_logits, top_k_indices = logits.topk(top_k, dim=-1)  # Get top-k experts

zeros = torch.full_like(logits, float('-inf')) 
sparse_logits = zeros.scatter(-1, top_k_indices, top_k_logits)

gating_output= F.softmax(sparse_logits, dim=-1)
gating_output

```
This idea can be extended to a noisy top-k gating for load balancing

Essentially, you don't want all the tokens to be sent to the same set of 'favored' experts. You want a fine balance of exploitation and exploration. For this purpose, to load balance, it is helpful to add standard normal noise to the logits from the gating linear layer. This makes training more efficient![[Pasted image 20240516081829.png]]

```
class NoisyTopkRouter(nn.Module):
    def __init__(self, n_embed, num_experts, top_k):
        super(NoisyTopkRouter, self).__init__()
        self.top_k = top_k

        self.topkroute_linear = nn.Linear(n_embed, num_experts)
        self.noise_linear =nn.Linear(n_embed, num_experts)

    
    def forward(self, mh_output):
        logits = self.topkroute_linear(mh_output)
        noise_logits = self.noise_linear(mh_output)

        #Adding scaled unit gaussian noise to the logits
        noise = torch.randn_like(logits)*F.softplus(noise_logits)
        noisy_logits = logits + noise

        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)
        zeros = torch.full_like(noisy_logits, float('-inf'))
        sparse_logits = zeros.scatter(-1, indices, top_k_logits)
        router_output = F.softmax(sparse_logits, dim=-1)
        return router_output, indices
```

###  Creating a sparse Mixture of Experts module

The primary aspect of this process involves the gating network's output. After acquiring these results, the top k values are selectively multiplied with the outputs from the corresponding top-k experts for a given token. This selective multiplication forms a weighted sum, which constitutes the SparseMoe block's output

**The critical and challenging part of this process is to avoid unnecessary multiplications. It's essential to conduct forward passes only for the top_k experts and then compute this weighted sum.**

```
class SparseMoE(nn.Module):
    def __init__(self, n_embed, num_experts, top_k):
        super(SparseMoE, self).__init__()
        self.router = NoisyTopkRouter(n_embed, num_experts, top_k)
        self.experts = nn.ModuleList([Expert(n_embed) for _ in range(num_experts)])
        self.top_k = top_k

    def forward(self, x):
        gating_output, indices = self.router(x)
        final_output = torch.zeros_like(x)

        # Reshape inputs for batch processing
        flat_x = x.view(-1, x.size(-1))
        flat_gating_output = gating_output.view(-1, gating_output.size(-1))

        # Process each expert in parallel
        for i, expert in enumerate(self.experts):
            # Create a mask for the inputs where the current expert is in top-k
            expert_mask = (indices == i).any(dim=-1)
            flat_mask = expert_mask.view(-1)

            if flat_mask.any():
                expert_input = flat_x[flat_mask]
                expert_output = expert(expert_input)

                # Extract and apply gating scores
                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)
                weighted_output = expert_output * gating_scores

                # Update final output additively by indexing and adding
                final_output[expert_mask] += weighted_output.squeeze(1)

        return final_output
```

```python

import torch
import torch.nn as nn

#Let's test this out
num_experts = 8
top_k = 2
n_embd = 16
dropout=0.1

mh_output = torch.randn(4, 8, n_embd)  # Example multi-head attention output
sparse_moe = SparseMoE(n_embd, num_experts, top_k)
final_output = sparse_moe(mh_output)
print("Shape of the final output:", final_output.shape)

Shape of the final output: torch.Size([4, 8, 16])
```
### Initialization details

Initialization is important for efficient training of deep neural nets. Kaiming He initialization is used here because of presence of ReLU activations in the experts. Feel free to experiment with Glorot initialization which is more commonly used in transformers.

```
def kaiming_init_weights(m):
    if isinstance (m, (nn.Linear)): 
        init.kaiming_normal_(m.weight)

model = SparseMoELanguageModel()
model.apply(kaiming_init_weights)
```

### Altogether
```
class SparseMoELanguageModel(nn.Module):

    def __init__(self):
        super().__init__()
        # each token directly reads off the logits for the next token from a lookup table
        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)
        self.position_embedding_table = nn.Embedding(block_size, n_embed)
        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head, num_experts=num_experts,top_k=top_k) for _ in range(n_layer)])
        self.ln_f = nn.LayerNorm(n_embed) # final layer norm
        self.lm_head = nn.Linear(n_embed, vocab_size)

    def forward(self, idx, targets=None):
        B, T = idx.shape

        # idx and targets are both (B,T) tensor of integers
        tok_emb = self.token_embedding_table(idx) # (B,T,C)
        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)
        x = tok_emb + pos_emb # (B,T,C)
        x = self.blocks(x) # (B,T,C)
        x = self.ln_f(x) # (B,T,C)
        logits = self.lm_head(x) # (B,T,vocab_size)

        if targets is None:
            loss = None
        else:
            B, T, C = logits.shape
            logits = logits.view(B*T, C)
            targets = targets.view(B*T)
            loss = F.cross_entropy(logits, targets)

        return logits, loss

    def generate(self, idx, max_new_tokens):
        # idx is (B, T) array of indices in the current context
        for _ in range(max_new_tokens):
            # crop idx to the last block_size tokens
            idx_cond = idx[:, -block_size:]
            # get the predictions
            logits, loss = self(idx_cond)
            # focus only on the last time step
            logits = logits[:, -1, :] # becomes (B, C)
            # apply softmax to get probabilities
            probs = F.softmax(logits, dim=-1) # (B, C)
            # sample from the distribution
            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
            # append sampled index to the running sequence
            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
        return idx

```
### Training

```python

#Using MLFlow
m = model.to(device)
# print the number of parameters in the model
print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')

# create a PyTorch optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
#mlflow.set_experiment("makeMoE")
with mlflow.start_run():
    #If you use mlflow.autolog() this will be automatically logged. I chose to explicitly log here for completeness
    params = {"batch_size": batch_size , "block_size" : block_size, "max_iters": max_iters, "eval_interval": eval_interval,
              "learning_rate": learning_rate, "device": device, "eval_iters": eval_iters, "dropout" : dropout, "num_experts": num_experts, "top_k": top_k }
    mlflow.log_params(params)
    for iter in range(max_iters):

        # every once in a while evaluate the loss on train and val sets
        if iter % eval_interval == 0 or iter == max_iters - 1:
            losses = estimate_loss()
            print(f"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
            metrics = {"train_loss": losses['train'], "val_loss": losses['val']}
            mlflow.log_metrics(metrics, step=iter)


        # sample a batch of data
        xb, yb = get_batch('train')

        # evaluate the loss
        logits, loss = model(xb, yb)
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
```

# Autoencoders
**Autoencoders**¬†are a specific type of feedforward neural networks where the input is the same as the output. They compress the input into a lower-dimensional latent representation and then reconstruct the output from this representation.
![[0_32-VK98ppmMz-Ogj.webp]]
Autoencoders are mainly used for¬†**dimensionality reduction**¬†(or compression) with a couple of important properties:

- Autoencoders are only able to meaningfully compress data similar to what they have been trained on. Since they learn features specific for the given training data, they are different than a standard data compression algorithm like gzip. So we can‚Äôt expect an autoencoder trained on handwritten digits to compress landscape photos.
- The output of the autoencoder will not be exactly the same as the input, it will be a close but degraded representation. If you want lossless compression they are not the way to go.
- To train an autoencoder we don‚Äôt need to do anything fancy, just throw the raw input data at it. Autoencoders are considered an unsupervised learning technique since they don‚Äôt need explicit labels to train on. But to be more precise they are self-supervised because they generate their own labels from the training data.

There are¬†**4 hyperparameters**¬†that we need to set before training an autoencoder:
- Latent vector dimensions
- Loss 
- number of layers
- nodes per layer

## Variants of AEs

Convolutional autoencoders leverage convolutional layers to excel in image-related tasks, capturing spatial relationships effectively. Sparse autoencoders introduce sparsity constraints on the latent space activations, aiding feature learning and dimensionality reduction. Denoising autoencoders tackle noise by training on corrupted versions of input data, leading to robust feature extraction. Contractive autoencoders include penalty terms in the loss function to enhance stability and reduce sensitivity to input variations. Stacked autoencoders combine multiple layers of autoencoders to create deep architectures for hierarchical feature learning. Finally, variational autoencoders (VAEs) inject probabilistic elements into the latent space, enabling data generation and intricate feature disentanglement. Now, we will go over a few details of Sparse AE and Denoising AE.

### Sparse AE
A sparse autoencoder is simply an autoencoder whose training criterion involves a sparsity penalty. In most cases, we would construct our loss function by penalizing activations of hidden layers so that only a few nodes are encouraged to activate when a single sample is fed into the network.

So, in sparse autoencoder we add L1 penalty to the loss to learn sparse feature representations. L1 regularization adds ‚Äúabsolute value of magnitude‚Äù of coefficients as penalty term. Although L1 and L2 can both be used as regularization term, the key difference between them is that L1 regularization tends to shrink the penalty coefficient to zero while L2 regularization would move coefficients towards zero but they will never reach. Thus L1 regularization is often used as a method of feature extraction. Hence the loss function will be:![[0_FfUAFQxja8EUqzpu.webp]]
### Denoising AE
### Convolutional AE
### Variational AE

A variational autoencoder (VAE) converts the input data to a variational representation vector (as the name suggests), where the elements of this vector represent different attributes about the input data distribution. This¬†_probabilistic_¬†property of the VAE makes it a generative model.

**The latent representation in VAE is composed of a probability distribution (_Œº,_¬†œÉ) that best defines our input data**

in order to be able to use the decoder of our autoencoder for generative purpose, we have to be sure that the latent space is regular enough. One possible solution to obtain such regularity is to introduce explicit regularisation during the training process. Thus, as we briefly mentioned in the introduction of this post, **a variational autoencoder can be defined as being an autoencoder whose training is regularised to avoid overfitting and ensure that the latent space has good properties that enable generative process.**

In order to introduce some regularisation of the latent space, we proceed to a slight modification of the encoding-decoding process:¬†**instead of encoding an input as a single point, we encode it as a distribution over the latent space**.

The model is then trained as follows:

- first, the input is encoded as distribution over the latent space
- second, a point from the latent space is sampled from that distribution
- third, the sampled point is decoded and the reconstruction error can be computed
- finally, the reconstruction error is backpropagated through the network

In practice, the encoded distributions are chosen to be normal so that the encoder can be trained to return the mean and the covariance matrix that describe these Gaussians.

**The loss function that is minimised when training a VAE is composed of a ‚Äúreconstruction term‚Äù (on the final layer), that tends to make the encoding-decoding scheme as performant as possible, and a ‚Äúregularisation term‚Äù (on the latent layer), that tends to regularise the organisation of the latent space by making the distributions returned by the encoder close to a standard normal distribution. That regularisation term is expressed as the¬†[Kulback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)¬†between the returned distribution and a standard Gaussian**
![[1_Q5dogodt3wzKKktE0v3dMQ@2x.webp]]
####  Intuitions about the regularisation

The regularity that is expected from the latent space in order to make generative process possible can be expressed through two main properties:¬†**continuity**¬†(two close points in the latent space should not give two completely different contents once decoded) and¬†**completeness**¬†(for a chosen distribution, a point sampled from the latent space should give ‚Äúmeaningful‚Äù content once decoded)

The only fact that VAEs encode inputs as distributions instead of simple points is not sufficient to ensure continuity and completeness. Without a well defined regularisation term, the model can learn, in order to minimise its reconstruction error,¬†**to ‚Äúignore‚Äù the fact that distributions are returned and behave almost like classic autoencoders**¬†(leading to overfitting). To do so, the encoder can either return distributions with tiny variances (that would tend to be punctual distributions) or return distributions with very different means (that would then be really far apart from each other in the latent space). In both cases, distributions are used the wrong way (cancelling the expected benefit) and continuity and/or completeness are not satisfied.

So, in order to avoid these effects¬†**we have to regularise both the covariance matrix and the mean of the distributions returned by the encoder**. In practice, this regularisation is done by enforcing distributions to be close to a standard normal distribution (centred and reduced). This way, we require the covariance matrices to be close to the identity, preventing punctual distributions, and the mean to be close to 0, preventing encoded distributions to be too far apart from each others.

we can observe that continuity and completeness obtained with regularisation¬†**tend to create a ‚Äúgradient‚Äù over the information encoded in the latent space**. For example, a point of the latent space that would be halfway between the means of two encoded distributions coming from different training data should be decoded in something that is somewhere between the data that gave the first distribution and the data that gave the second distribution as it may be sampled by the autoencoder in both cases.

#### Mathematical details

Let‚Äôs begin by defining a probabilistic graphical model to describe our data. We denote by x the variable that represents our data and assume that x is generated from a latent variable z.

Thus, for each data point, the following two steps generative process is assumed:

- first, a latent representation z is sampled from the prior distribution p(z)
- second, the data x is sampled from the conditional likelihood distribution p(x|z)

The ‚Äúprobabilistic decoder‚Äù is naturally defined by¬†**p(x|z), that describes the distribution of the decoded variable given the encoded one**, whereas the ‚Äúprobabilistic encoder‚Äù is defined by¬†**p(z|x), that describes the distribution of the encoded variable given the decoded one**.

At this point, we can already notice that the regularisation of the latent space that we lacked in simple autoencoders naturally appears here in the definition of the data generation process: encoded representations z in the latent space are indeed assumed to follow the prior distribution p(z). Otherwise, we can also remind the the well-known Bayes theorem that makes the link between the prior p(z), the likelihood p(x|z), and the posterior p(z|x)

![[Pasted image 20240521011548.png]]

Let‚Äôs now make the assumption that p(z) is a standard Gaussian distribution and that p(x|z) is a Gaussian distribution whose mean is defined by a deterministic function f of the variable of z and whose covariance matrix has the form of a positive constant c that multiplies the identity matrix.

he function f is assumed to belong to a family of functions denoted F that is left unspecified for the moment and that will be chosen later. Thus, we have

![[Pasted image 20240521012150.png]]
Let‚Äôs consider, for now, that f is well defined and fixed. In theory, as we know p(z) and p(x|z), we can use the Bayes theorem to compute p(z|x): this is a classical¬†[Bayesian inference problem](https://towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29).

In statistics,¬†**variational inference (VI) is a technique to approximate complex distributions**. The idea is to set a parametrised family of distribution (for example the family of Gaussians, whose parameters are the mean and the covariance) and to look for the best approximation of our target distribution among this family. The best element in the family is one that minimise a given approximation error measurement (most of the time the Kullback-Leibler divergence between approximation and target) and is found by gradient descent over the parameters that describe the family.

Here we are going to approximate p(z|x) by a Gaussian distribution q_x(z) whose mean and covariance are defined by two functions, g and h, of the parameter x. These two functions are supposed to belong, respectively, to the families of functions G and H that will be specified later but that are supposed to be parametrised. Thus we can denote:

![[Pasted image 20240521012438.png]]
So, we have defined this way a family of candidates for variational inference and need now to find the best approximation among this family by optimising the functions g and h to minimise the Kullback-Leibler divergence between the approximation and the target p(z|x).

![[Pasted image 20240521012622.png]]
Up to know, we have assumed the function f known and fixed and we have showed that, under such assumptions, we can approximate the posterior p(z|x) using variational inference technique. However, in practice this function f, that defines the decoder, is not known and also need to be chosen.

**For a given input x, we want to maximise the probability to have xÃÇ = x when we sample z from the distribution q*_x(z) and then sample xÃÇ from the distribution p(x|z).**¬†Thus, we are looking for the optimal f* such that

![[Pasted image 20240521013449.png]]
The higher c is the more we assume a high variance around f(z) for the probabilistic decoder in our model and, so, the more we favour the regularisation term over the reconstruction term (and the opposite stands if c is low).
#### Bringing neural networks into the model

¬†As we can‚Äôt easily optimise over the entire space of functions, we constrain the optimisation domain and decide to express f, g and h as neural networks. Thus, F, G and H correspond respectively to the families of functions defined by the networks architectures and the optimisation is done over the parameters of these networks.

In practice, g and h are not defined by two completely independent networks but share a part of their architecture and their weights so that we have.
![[Pasted image 20240521014127.png]]
As it defines the covariance matrix of q_x(z), h(x) is supposed to be a square matrix. However, in order to simplify the computation and reduce the number of parameters, we make the additional assumption that our approximation of p(z|x), q_x(z), is a multidimensional Gaussian distribution with diagonal covariance matrix (variables independence assumption). With this assumption, h(x) is simply the vector of the diagonal elements of the covariance matrix and has then the same size as g(x). However, we reduce this way the family of distributions we consider for variational inference and, so, the approximation of p(z|x) obtained can be less accurate.


Our model assumes for p(x|z) a Gaussian with fixed covariance. The function f of the variable z defining the mean of that Gaussian is modelled by a neural network and can be represented as follows

![[Pasted image 20240521015448.png]]
The overall architecture is then obtained by concatenating the encoder and the decoder parts. However we still need to be very careful about the way we sample from the distribution returned by the encoder during the training. The sampling process has to be expressed in a way that allows the error to be backpropagated through the network.

¬†A simple trick, called¬†**reparametrisation trick**, is used to make the gradient descent possible despite the random sampling that occurs halfway of the architecture and consists in using the fact that if z is a random variable following a Gaussian distribution with mean g(x) and with covariance H(x)=h(x).h^t(x) then it can be expressed as:

![[Pasted image 20240521015629.png]]
![[Pasted image 20240521015744.png]]
Finally, the objective function of the variational autoencoder architecture obtained this way is given by the last equation of the previous subsection in which the theoretical expectancy is replaced by a more or less accurate Monte-Carlo approximation that consists, most of the time, into a single draw. 

So, considering this approximation and denoting C = 1/(2c), we recover the loss function derived intuitively in the previous section, composed of a reconstruction term, a regularisation term and a constant to define the relative weights of these two terms.

![[Pasted image 20240521015856.png]]
#### PyTorch code

The input dimension is 784 which is the flattened dimension of MNIST images (28√ó28). In the encoder, the mean (Œº) and variance (œÉ¬≤) vectors are our variational representation vectors (size=200). Notice that we multiply the latent variance with the epsilon (Œµ) parameter for reparameterization before decoding. This allows us to perform backpropagation and tackle the node stochasticity.

Also, our final encoder dimension has dimension 2 which are the Œº and œÉ vectors. These continuous vectors define our latent space distribution that allows us to sample images in VAE.

```
class VAE(nn.Module):  
  
def __init__(self, input_dim=784, hidden_dim=400, latent_dim=200, device=device):  
super(VAE, self).__init__()  
  
# encoder  
self.encoder = nn.Sequential(  
nn.Linear(input_dim, hidden_dim),  
nn.LeakyReLU(0.2),  
nn.Linear(hidden_dim, latent_dim),  
nn.LeakyReLU(0.2)  
)  
  
# latent mean and variance  
self.mean_layer = nn.Linear(latent_dim, 2)  
self.logvar_layer = nn.Linear(latent_dim, 2)  
  
# decoder  
self.decoder = nn.Sequential(  
nn.Linear(2, latent_dim),  
nn.LeakyReLU(0.2),  
nn.Linear(latent_dim, hidden_dim),  
nn.LeakyReLU(0.2),  
nn.Linear(hidden_dim, input_dim),  
nn.Sigmoid()  
)  
  
def encode(self, x):  
x = self.encoder(x)  
mean, logvar = self.mean_layer(x), self.logvar_layer(x)  
return mean, logvar  
  
def reparameterization(self, mean, var):  
epsilon = torch.randn_like(var).to(device)  
z = mean + var*epsilon  
return z  
  
def decode(self, x):  
return self.decoder(x)  
  
def forward(self, x):  
mean, logvar = self.encode(x)  
z = self.reparameterization(mean, logvar)  
x_hat = self.decode(z)  
return x_hat, mean, log_var

```

```
model = VAE().to(device)  
optimizer = Adam(model.parameters(), lr=1e-3)
```

The loss function in VAE consists of reproduction loss and the Kullback‚ÄìLeibler (KL) divergence. The KL divergence is a metric used to measure the distance between two probability distributions.

```
def loss_function(x, x_hat, mean, log_var):  
reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')  
KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())  
  
return reproduction_loss + KLD
```

Simple training: 

```
def train(model, optimizer, epochs, device):  
model.train()  
for epoch in range(epochs):  
overall_loss = 0  
for batch_idx, (x, _) in enumerate(train_loader):  
x = x.view(batch_size, x_dim).to(device)  
  
optimizer.zero_grad()  
  
x_hat, mean, log_var = model(x)  
loss = loss_function(x, x_hat, mean, log_var)  
  
overall_loss += loss.item()  
  
loss.backward()  
optimizer.step()  
  
print("\tEpoch", epoch + 1, "\tAverage Loss: ", overall_loss/(batch_idx*batch_size))  
return overall_loss  
  
train(model, optimizer, epochs=50, device=device)
```

To generate a simple image is to:
```
def generate_digit(mean, var):  
z_sample = torch.tensor([[mean, var]], dtype=torch.float).to(device)  
x_decoded = model.decode(z_sample)  
digit = x_decoded.detach().cpu().reshape(28, 28) # reshape vector to 2d array  
plt.imshow(digit, cmap='gray')  
plt.axis('off')  
plt.show()  
  
generate_digit(0.0, 1.0), generate_digit(1.0, 0.0)
```

## Limitations
1. Deterministic
2. ¬†Computationally expensive when dealing with large and complex datasets

¬†¬†While they can be used to generate reconstructions of the input data, they do not inherently learn to generate entirely new data samples from scratch. The primary objective of autoencoders is to capture the most informative and relevant features in the data and produce accurate reconstructions. The latent space learned by autoencoders does not follow any specific probability distribution. Thus the AEs are deterministic and not generative.

Sampling from the vanilla autoencoders is also difficult because its learned distribution is oddly shaped, discontinuous, and not centered at (0,0). There are areas called as holes with no points between the images of different types. Thus, if a point is randomly picked up from this empty space, it is not certain whether the desired images will get created. Autoencoder has no way to ensure that the points in the latent space are continuous in nature.

# DSSM (deep semantic similarity model) –∏ –ø—Ä–∏—á—ë–º —Ç—É—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è

–û–Ω–∞ –±—ã–ª–∞ –æ–ø–∏—Å–∞–Ω–∞ –≤ 2013 –≥–æ–¥—É, –≤¬†[—Å—Ç–∞—Ç—å–µ –æ—Ç Microsoft](https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data), –≥–¥–µ –æ–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ —Ç–∞–∫—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –¥–ª—è –∫–∞–∂–¥–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ –≤—ã–¥–µ–ª—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–∞—è –≤–µ—Ç–≤—å, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∞—è—Å—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —ç—Ç–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ ‚Äî –≤–µ–∫—Ç–æ—Ä–æ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º. –ú—ã —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã —ç—Ç–∏ –≤–µ–∫—Ç–æ—Ä—ã –æ–±–ª–∞–¥–∞–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Å–≤–æ–π—Å—Ç–≤–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –¥–≤–µ —Å—É—â–Ω–æ—Å—Ç–∏ –ø–æ—Ö–æ–∂–∏ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞, —Ç–æ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º –≤–µ–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –±–ª–∏–∑–∫–∏ –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –ê –µ—Å–ª–∏ —ç—Ç–∏ —Å—É—â–Ω–æ—Å—Ç–∏ –Ω–∏–∫–∞–∫ –Ω–µ —Å–≤—è–∑–∞–Ω—ã, —Ç–æ –∏ –≤–µ–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ —Ä–∞–∑–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã.

![[Pasted image 20240529164510.png]]
![[Pasted image 20240529164557.png]]

> –ù–æ, –ø–æ–∂–∞–ª—É–π, —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –º–µ—Å—Ç–æ –≤ —ç—Ç–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∑–∞–Ω–∏–º–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ –æ–ø—ã—Ç–∞ –≤ —Ä–µ–∑—é–º–µ. –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç –º—ã –ø–µ—Ä–µ–¥–∞–µ–º –Ω–∞ –≤—Ö–æ–¥ —Å–ª–æ—é RNN, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞ –≤—ã—Ö–æ–¥–µ –≤—ã–¥–∞–µ—Ç –ø–æ –æ–¥–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä—É –Ω–∞ –∫–∞–∂–¥—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω, –¥–∞–ª–µ–µ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º —ç—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∞ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Å—Ç–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ attention-—Å–ª–æ—è, –∑–∞—Ç–µ–º –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –ø—Ä–æ–≥–æ–Ω—è–µ–º –µ—â–µ —á–µ—Ä–µ–∑ –ø–∞—Ä—É —Å–ª–æ–µ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º —Ç–æ—Ç —Å–∞–º—ã–π –∂–µ–ª–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–ª–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —É –Ω–∞—Å —Ç–∞–∫–∂–µ –µ—Å—Ç—å –∏ –¥–ª—è —Ä–µ–∑—é–º–µ, –æ–Ω–∞ –±—É–¥–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä–æ–º –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –º—ã —Ç–æ–∂–µ –ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Ä–µ–∑—é–º–µ.
> –ü–æ–ª—É—á–∏–≤ –¥–≤–∞ –≤–µ–∫—Ç–æ—Ä–∞ –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ —Ä–µ–∑—é–º–µ, –º—ã –º–æ–∂–µ–º –Ω–∞–π—Ç–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –Ω–∏–º–∏ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è. –ú—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ —Ä–µ–∑—é–º–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ—Ö–æ–∂–∏ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞, –µ—Å–ª–∏ –º–µ–∂–¥—É –Ω–∏–º–∏ –±—ã–ª –∫–∞–∫–æ–π-—Ç–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Å–∏–≥–Ω–∞–ª. –ù–∞–ø—Ä–∏–º–µ—Ä, –±—ã–ª –æ—Ç–∫–ª–∏–∫ –Ω–∞ —ç—Ç—É –≤–∞–∫–∞–Ω—Å–∏—é –æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏–ª–∏ –±—ã–ª–æ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é. –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –º–æ–∂–µ–º –Ω–∞—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –ª–∏–±–æ —Å–ª—É—á–∞–π–Ω–æ, –ª–∏–±–æ –≤–∑—è–≤ —Ç–µ –≤–∞–∫–∞–Ω—Å–∏–∏, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —á–µ–ª–æ–≤–µ–∫ –ø—Ä–æ—Å—Ç–æ –ø–æ—Å–º–æ—Ç—Ä–µ–ª, –Ω–æ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –Ω–µ —Å–¥–µ–ª–∞–ª.
> –ù–∞ –≤—Ö–æ–¥ —Å–ª–æ—é RNN –º—ã –¥–∞–µ–º –Ω–µ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ —Ä–µ–∑—é–º–µ, –∞ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 300 —Ç–æ–∫–µ–Ω–æ–≤.


¬†–°–µ—Ä—ã–º –≤—ã–¥–µ–ª–µ–Ω–æ —Ç–æ, —á—Ç–æ –Ω–µ –ø–æ–º–µ—Å—Ç–∏–ª–æ—Å—å –≤ –ø–µ—Ä–≤—ã–µ 300 —Ç–æ–∫–µ–Ω–æ–≤, –∏ –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü –∑–∞–Ω—è–ª –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞, –∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –Ω–µ –≤–ª–µ–∑–ª–∏ –≤–æ–≤—Å–µ. –û—Ç—Å—é–¥–∞ —É –Ω–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∞ –∏–¥–µ—è –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–∞–∫—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–¥–µ–ª—è—Ç—å —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ —á–∞—Å—Ç–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞. –¢–æ–≥–¥–∞ –º—ã –ø–æ–ª—É—á–∏–º –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–µ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–¢–∞–∫ —É –Ω–∞—Å —Ä–æ–¥–∏–ª–∞—Å—å –∑–∞–¥–∞—á–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ ‚Äî –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.


**–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —Ä–µ—à–µ–Ω–∏—é –∑–∞–¥–∞—á–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ ‚Äî –æ–Ω–∏ –¥–µ–ª—è—Ç—Å—è –Ω–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ. –≠–∫—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã ‚Äî —ç—Ç–æ –∫–æ–≥–¥–∞ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫—É—Å–æ—á–∫–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ —Ç–æ–º –≤–∏–¥–µ, –∫–∞–∫ –æ–Ω–∏ –±—ã–ª–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ. –ê–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è ‚Äî —ç—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω–æ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç, –≥–¥–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å—Å—è —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞–∂–µ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ç–µ–∫—Å—Ç–µ.**

–°–ª–µ–¥—É—é—â–µ–µ –¥–µ–ª–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ —Ä–µ—à–µ–Ω–∏—é –∑–∞–¥–∞—á–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ supervised- –∏ unsupervised-learning. –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä –ø–æ–¥—Ö–æ–¥–∞ unsupervised-learning ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º¬†[TextRank](https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09), –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: –º—ã –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∫–∞–∂–¥–æ–µ, –∞ –∑–∞—Ç–µ–º —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ, –≥–¥–µ –≤–µ—Ä—à–∏–Ω–∞–º–∏ —Å—Ç–∞–Ω—É—Ç –Ω–∞—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∞ —Ä–µ–±—Ä–∞ –º—ã –≤–∑–≤–µ—Å–∏–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏ –º–µ–∂–¥—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏.

–ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ –∫–∞–∫ –ø–æ—Å—á–∏—Ç–∞—Ç—å —ç—Ç–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è ‚Äî —Ä–æ–∂–¥–∞–µ—Ç—Å—è –º–∞—Å—Å–∞ –≤–∞—Ä–∏–∞—Ü–∏–π —ç—Ç–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞. –ù–æ –ø–æ—Ç–æ–º –º—ã –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–∞ —ç—Ç–æ–º –≥—Ä–∞—Ñ–µ –∞–ª–≥–æ—Ä–∏—Ç–º PageRank, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–¥–∞–µ—Ç –Ω–∞–º —Å–∫–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ä—à–∏–Ω—ã, –∏ —ç—Ç–∏ —Å–∫–æ—Ä—ã –º—ã —É–∂–µ –º–æ–∂–µ–º –ø—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –±–µ—Ä–µ–º —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Å—Ç—Ä–æ–∏–º –∏–∑ –Ω–∏—Ö —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é.

–ù–∞—à –≤—ã–±–æ—Ä ‚Äî —ç—Ç–æ supervised-learning. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –≤—ã–±–æ—Ä–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º. –í –Ω–µ–º –±—É–¥–µ—Ç —É–∫–∞–∑–∞–Ω–æ, –∫–∞–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –∏ –µ–≥–æ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –≤ —Å–∞–º–º–∞—Ä–∏, –∞ –∫–∞–∫–æ–µ ‚Äî –Ω–µ—Ç.

–û–¥–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ ‚Äî –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ç–∞–∫–æ–π —Å—ç–º–ø–ª –≤—Ä—É—á–Ω—É—é –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ—Ä–µ–∞–ª—å–Ω–æ. –ß—Ç–æ–±—ã —á–µ–ª–æ–≤–µ–∫—É –≤—Ä—É—á–Ω—É—é —Ä–∞–∑–º–µ—Ç–∏—Ç—å –æ–¥–Ω—É –≤–∞–∫–∞–Ω—Å–∏—é, –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –î–∞ –∏ –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ –Ω–µ –¥–æ –∫–æ–Ω—Ü–∞ –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –µ–º—É –Ω—É–∂–Ω–æ —Ä–∞–∑–º–µ—á–∞—Ç—å, –ø–æ—Ç–æ–º—É —á—Ç–æ –∑–∞–¥–∞—á–∞ —Å—Ç–æ–∏—Ç –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ ‚Äî –æ—Ç–æ–±—Ä–∞—Ç—å —Ç–∞–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –≤—ã–±—Ä–∞–≤ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö 300 —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–µ—Ä–µ–¥–∞–≤ –∏—Ö –Ω–∞ –≤—Ö–æ–¥ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ DSSM, –º—ã –ø–æ–ª—É—á–∏–º –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ù–æ –∫–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è? –¢—É—Ç —É –Ω–∞—Å —Ä–æ–¥–∏–ª–∞—Å—å —Å–ª–µ–¥—É—é—â–∞—è –∏–¥–µ—è. –ü–æ—á–µ–º—É –±—ã –Ω–µ —Å–ø—Ä–æ—Å–∏—Ç—å —É —Å–∞–º–æ–π –º–æ–¥–µ–ª–∏ DSSM, —á—Ç–æ –µ–π –≤–∞–∂–Ω–æ, –∞ —á—Ç–æ –Ω–µ—Ç.

–í–µ—Ä–Ω–µ–º—Å—è –∫ –Ω–∞—à–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ DSSM –∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ä–∞–∑–±–µ—Ä–µ–º —Å–ª–æ–π –ª–∏–Ω–µ–π–Ω–æ–≥–æ –∞—Ç—Ç–µ–Ω—à–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π —è —É–ø–æ–º–∏–Ω–∞–ª —Ä–∞–Ω–µ–µ. –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —ç—Ç–æ—Ç —Å–ª–æ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–æ–π. –í–æ-–ø–µ—Ä–≤—ã—Ö, –Ω–∞ –≤—Ö–æ–¥ –≤ —Å–ª–æ–π RNN —É –Ω–∞—Å –ø–æ—Å—Ç—É–ø–∞–µ—Ç 300 —Ç–æ–∫–µ–Ω–æ–≤, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –º—ã –ø–æ–ª—É—á–∞–µ–º –ø–æ –≤–µ–∫—Ç–æ—Ä—É –Ω–∞ –∫–∞–∂–¥—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω. –ì—Ä—É–±–æ –≥–æ–≤–æ—Ä—è, 300 –≤–µ–∫—Ç–æ—Ä–æ–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 256.

–î–∞–ª–µ–µ —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–µ–º–Ω–æ–∂–∞–µ—Ç –∫–∞–∂–¥—ã–π —ç—Ç–æ—Ç –≤–µ–∫—Ç–æ—Ä, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –¥–∞–µ—Ç –Ω–∞–º –æ–¥–Ω–æ —á–∏—Å–ª–æ ‚Äî –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 300. –¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç –≤–µ–∫—Ç–æ—Ä –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —á–µ—Ä–µ–∑ softmax, –∫–æ—Ç–æ—Ä—ã–π –µ–≥–æ –Ω–æ—Ä–º–∏—Ä—É–µ—Ç, –∏ –≤ –∏—Ç–æ–≥–µ –ø–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞. –≠—Ç–∏ –≤–µ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ—Å—á–∏—Ç–∞—Ç—å –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É –≤—ã—Ö–æ–¥–æ–≤ –∏–∑ RNN –∏ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 256.

–ó–∞ —Å—á–µ—Ç —ç—Ç–æ–π —Å—Ö–µ–º—ã –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Å–∞–º–∞, –∫–∞–∫–æ–º—É —Ç–æ–∫–µ–Ω—É –ø—Ä–∏–¥–∞—Ç—å –±–æ–ª—å—à–µ –≤–µ—Å–∞, –∫–∞–∫–æ–º—É –º–µ–Ω—å—à–µ. –ü—Ä–æ—â–µ –≥–æ–≤–æ—Ä—è, –æ—Ç –∫–∞–∫–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤–∑—è—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —ç—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–π —Å—É–º–º–µ, –∞ –∫–∞–∫–æ–π –≤–µ–∫—Ç–æ—Ä –º–æ–∂–Ω–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–Ω—É–ª–∏—Ç—å.

–ß–∞—Å—Ç—ã–π —Ç—Ä—é–∫ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ ‚Äî –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è, –∑–∞–º–µ–Ω–∞ —á–µ–≥–æ-—Ç–æ —Å–ª–æ–∂–Ω–æ–≥–æ –∏ –±–æ–ª—å—à–æ–≥–æ –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å—é. –ó–¥–µ—Å—å –º—ã —Ç–æ–∂–µ –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ—Ç —Ç—Ä—é–∫ –∏ –æ–±—É—á–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—É—é –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª–∞ —Ä–∞–∑–º–µ—Ç–∫—É –∞—Ç—Ç–∞–Ω—à–µ–Ω–∞ –Ω–∞—à–µ–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º—ã –±—ã –∏ —Ä–µ—à–∏–ª–∏ –∑–∞–¥–∞—á—É —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏, —Ç–æ –µ—Å—Ç—å –±—ã –≤—ã–¥–µ–ª—è–ª–∏ —Ç–µ —á–∞—Å—Ç–∏ –≤–∞–∫–∞–Ω—Å–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–∞–º—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

![[Pasted image 20240529165420.png]]



–†–∞–±–æ—Ç—É –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å—Ç—Ä–æ–∏–º —Å—ç–º–ø–ª –∏ –¥–∞–ª–µ–µ. –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–Ω—É—é –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é, –∫–æ—Ç–æ—Ä–∞—è, –∫–∞–∫ –∏–∑–≤–µ—Å—Ç–Ω–æ, –≤—ã–¥–∞–µ—Ç –Ω–∞–º –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç –Ω—É–ª—è –¥–æ –µ–¥–∏–Ω–∏—Ü—ã. –≠—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –º—ã –º–æ–∂–µ–º –ø—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –î–∞–ª–µ–µ —Å–æ—Ä—Ç–∏—Ä—É–µ–º —ç—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∏—Å—Ö–æ–¥—è –∏–∑ —ç—Ç–æ–≥–æ —Å–∫–æ—Ä–∞, –∏ –æ—Ç–±–∏—Ä–∞–µ–º –∏–∑ –Ω–∏—Ö —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ, –ø–æ–∫–∞ –Ω–µ –Ω–∞–±–µ—Ä–µ—Ç—Å—è 300 —Ç–æ–∫–µ–Ω–æ–≤. –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ –≤—ã–∫–∏–¥—ã–≤–∞–µ–º. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —É –Ω–∞—Å –æ—Å—Ç–∞–µ—Ç—Å—è —Å–∞–º–º–∞—Ä–∏ –∏–∑ —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –≤ –∏—Ç–æ–≥–µ –º—ã –µ—â–µ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –∫–∞–∫ –æ–Ω–∏ —à–ª–∏ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ

![[Pasted image 20240529165620.png]]


# MAB and CAB

## –ì–ª–æ—Å—Å–∞—Ä–∏–π 
```
**–í–∞—Ä–∏–∞–Ω—Ç (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è, action, arm)**¬†- –∞–Ω–∞–ª–æ–≥ –≥—Ä—É–ø–ø—ã –≤ A/B-—Ç–µ—Å—Ç–µ. –ö–∞–∫–æ–µ-—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å—Ä–∞–≤–Ω–∏—Ç—å —Å —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏–ª–∏ —á–µ–º-–ª–∏–±–æ –µ—â–µ.

**–ù–∞–≥—Ä–∞–¥–∞ (—Ü–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞, reward)**¬†- –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–æ –æ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–≥–æ –∏–ª–∏ –∏–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞.

**–£–±—ã—Ç–æ–∫ (regret)**¬†- –ø–æ—Ç–µ—Ä–∏ –≤ –Ω–∞–≥—Ä–∞–¥–µ –æ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–≥–æ –∏–ª–∏ –∏–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞.

**–°—Ä–µ–¥–∞**¬†- —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É—Å–ª–æ–≤–∏–π –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Å—É–±—ä–µ–∫—Ç–æ–≤ —Å—Ä–µ–¥—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: —Ä—ã–Ω–æ–∫ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤).

**–ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ñ–∞–∫—Ç–æ—Ä—ã)**¬†- –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏–µ —Å—É–±—ä–µ–∫—Ç–∞ —Å—Ä–µ–¥—ã (–ø–æ–ª, –≤–æ–∑—Ä–∞—Å—Ç, —Å—Ç—Ä–∞–Ω–∞).
```

## –°—É—Ç—å
![[Pasted image 20240531144955.png]]

**–ú–Ω–æ–≥–æ—Ä—É–∫–∏–π –±–∞–Ω–¥–∏—Ç**¬†‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π, —Å—É—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–∏ –±–∞–ª–∞–Ω—Å–∞ –º–µ–∂–¥—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞–∫–æ–≥–æ-—Ç–æ –∏–∑ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–µ—à–µ–Ω–∏—è —Å —Ü–µ–ª—å—é –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–∏ –∏ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —É–±—ã—Ç–∫–æ–≤.

1. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–Ω–æ–≥–æ—Ä—É–∫–∏–µ –±–∞–Ω–¥–∏—Ç—ã (MAB). –≠—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–¥–Ω–æ–≥–æ —Å–∞–º–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä–∞–¥–æ–π. –≠—Ç–æ —Å–∞–º—ã–π —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ç–∏–ø –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–æ–≤, –∫ –Ω–µ–º—É –æ—Ç–Ω–æ—Å—è—Ç—Å—è —à–∏—Ä–æ–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ MAB: epsilon-greedy, UCB, Thompson sampling. –ê–ª–≥–æ—Ä–∏—Ç–º—ã MAB –Ω–µ —Å–ø–æ—Å–æ–±–Ω—ã —É–ª–∞–≤–ª–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥—ã, –≤ –∫–æ—Ç–æ—Ä–æ–π —Ä–∞–±–æ—Ç–∞—é—Ç, ‚Äî –æ–Ω–∏ –ª–∏—à—å –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –≤–∞—Ä–∏–∞–Ω—Ç—ã, –≥–¥–µ —Å—Ä–µ–¥–Ω–µ—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª—å—à–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–∏.
2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –±–∞–Ω–¥–∏—Ç—ã (CMAB). –≠—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –Ω–∞–≥—Ä–∞–¥—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å—Ä–µ–¥—ã, –≤ –∫–æ—Ç–æ—Ä–æ–π –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç. –ù–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã CMAB —è–≤–ª—è—é—Ç—Å—è –ø–æ —Å–≤–æ–µ–π —Å—É—Ç–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏–µ–π epsilon-greedy, UCB, Thompson sampling –∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: linear epsilon-greedy, UCB, TS. 

–£ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ MAB –∏ CMAB –µ—Å—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏. –°—Ä–∞–∑—É –æ–±–æ–∑–Ω–∞—á—É: –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π –∑–∞–º–µ–Ω–æ–π A/B-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, —É –Ω–∏—Ö –µ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –Ω–∏—à–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–º. **–î–ª—è CMAB ‚Äî —ç—Ç–æ –∑–∞–¥–∞—á–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π: —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–æ, –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ä–µ–∫–ª–∞–º–∞ –∏ —Ç. –¥. –î–ª—è MAB —ç—Ç–æ –∑–∞–¥–∞—á–∏, –≥–¥–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω–æ —Ä–µ—à–µ–Ω–∏–µ, –Ω–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ A/B-—Ç–µ—Å—Ç–∞ –∑–∞—Ç—Ä—É–¥–Ω–µ–Ω–æ.**


1. –û–±–∞ —Ç–∏–ø–∞ –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–æ–≤ –º–æ–≥—É—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–∏—à—å –æ–¥–Ω—É –º–µ—Ç—Ä–∏–∫—É, –ø–æ—ç—Ç–æ–º—É –æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ –æ—Ç—Ä–∞–∂–∞—Ç—å —Å—É—Ç—å —Ä–µ—à–∞–µ–º–æ–π –∑–∞–¥–∞—á–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–≤—ã—Å–∏—Ç—å –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂, –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–∞—Ä–∂—É –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫–∏, –∞ –µ—Å–ª–∏ —Ü–µ–ª—å ‚Äî —É–≤–µ–ª–∏—á–∏—Ç—å CTR, —Ç–æ –æ—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ —Å–ª–µ–¥—É–µ—Ç –≤—ã–±—Ä–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω–≤–µ—Ä—Å–∏—é –≤ –∫–ª–∏–∫.¬†
    

2. CMAB –∏ MAB –º–æ–≥—É—Ç –ø—Ä–∏—Å–ø–æ—Å–∞–±–ª–∏–≤–∞—Ç—å—Å—è (–º–µ–Ω—è—è –≤—ã–∏–≥—Ä—ã—à–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç) –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º —É—Å–ª–æ–≤–∏–π —Å—Ä–µ–¥—ã, –∫–æ—Ç–æ—Ä—É—é –æ–Ω–∏ –∏—Å—Å–ª–µ–¥—É—é—Ç, –æ–¥–Ω–∞–∫–æ –¥–µ–ª–∞—é—Ç –æ–Ω–∏ —ç—Ç–æ –ø–æ-—Ä–∞–∑–Ω–æ–º—É. –ï—Å–ª–∏ –¥–ª—è CMAB —ç—Ç–æ –≤–æ–æ–±—â–µ –æ—Å–Ω–æ–≤–∞ —Ä–∞–±–æ—Ç—ã, —Ç–æ —Å MAB –¥–µ–ª–æ –æ–±—Å—Ç–æ–∏—Ç —Å–ª–æ–∂–Ω–µ–µ: —á–∞—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, –º–æ–∂–µ—Ç –∑–∞–º–µ—Ç–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –ª–∏–±–æ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ñ–∞–∫—Ç –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞. –ü–æ—Å–ª–µ–¥–Ω–µ–µ —á–∞—Å—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –Ω–∞ —Ä–∞–Ω–Ω–µ–º —ç—Ç–∞–ø–µ —Ä–∞–±–æ—Ç—ã MAB —Å—Ä–µ–¥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –±—ã–ª —è–≤–Ω—ã–π –ª–∏–¥–µ—Ä. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è UCB. –ß—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –ø–æ–¥–æ–±–Ω—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ —Å–¥–µ–ª–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º MAB —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º —Å—Ä–µ–¥—ã, —Å–ª–µ–¥—É–µ—Ç –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–∞—É–Ω–¥–æ–≤ —Å –ø–æ–ª–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –≤–µ—Å–æ–≤ MAB –ª–∏–±–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –≤ –∫–æ—Ç–æ—Ä—ã—Ö¬† –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–æ —Ä—É—á–Ω–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ —Ä—É—á–µ–∫ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π –æ –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö-–∞—É—Ç—Å–∞–π–¥–µ—Ä–∞—Ö –≤ —Ç–µ–∫—É—â–µ–º —Ä–∞—É–Ω–¥–µ –±–∞–Ω–¥–∏—Ç–∞.

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ MAB –∏ CMAB:

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- –≥–∏–±–∫–æ—Å—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç—Ä–∞—Ñ–∏–∫ –º–µ–∂–¥—É —Ö—É–¥—à–∏–º–∏ –∏ –ª—É—á—à–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —É–±—ã—Ç–∫–æ–≤;¬†
- –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É, –∫–æ–≥–¥–∞ A/B-—Ç–µ—Å—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –Ω–µ—Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ;¬†
- –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç (CMAB).¬†
–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:¬†
- –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫ –¥–ª—è —Ñ–∏–∫—Å–∞—Ü–∏–∏ —É—Ä–æ–≤–Ω–µ–π –æ—à–∏–±–æ–∫ I –∏ II —Ä–æ–¥–∞;¬†
- –º–æ—â–Ω–æ—Å—Ç—å MAB –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∂–µ, —á–µ–º —É A/B-—Ç–µ—Å—Ç–∞, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—á–µ–Ω—å –º–∞–ª–∞.

## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞ MAB

–û—Å–Ω–æ–≤–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–æ–≤ —è–≤–ª—è—é—Ç—Å—è:¬†

- **Œµ-greedy**¬†
- **UCB (upper confidence bound)**¬†
- **Thompson sampling.**

–°—É—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞¬†**Œµ-greedy**¬†–æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞: –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–Ω–µ–π –Ω–∞–≥—Ä–∞–¥–æ–π (—Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—É—é –º—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º) –∏ –∏–Ω–æ–≥–¥–∞ —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –∑–∞—Ä–∞–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.


**UCB**, –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç Œµ-greedy, –ø—Ä–æ–≤–æ–¥–∏—Ç —Å–≤–æ—ë –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ —Å–ª—É—á–∞–π–Ω–æ, –∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Ç—É—â–µ–π —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ —É —Å—Ç—Ä–∞—Ç–µ–≥–∏–π. –í –Ω–∞—á–∞–ª–µ —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º —Å–ª—É—á–∞–π–Ω–æ –∑–∞–¥–µ–π—Å—Ç–≤—É–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø–æ—Å–ª–µ —á–µ–≥–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ –∫–∞–∂–¥–æ–π. –î–∞–ª–µ–µ –≤—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:¬†
1. –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è —Å—Ä–µ–¥–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.¬†
2. –° —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ —á–µ–º —Ä–µ–∂–µ –≤—ã–±–∏—Ä–∞–ª–∞—Å—å —Ç–∞ –∏–ª–∏ –∏–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, —Ç–µ–º –±–æ–ª—å—à–µ –±—É–¥–µ—Ç —É –Ω–µ—ë –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å.¬†
3. –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –≤—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ ‚Äî —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—É–º–º–∞ —Å—Ä–µ–¥–Ω–µ–π –Ω–∞–≥—Ä–∞–¥—ã –∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π. 
![[Pasted image 20240531145912.png]]
–≥–¥–µ:¬†
- _Qt(a)_¬†‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏¬†_a_;¬†
- _t_¬†‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π;
- _Nt(a)_¬†‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, –∫–æ–≥–¥–∞ –±—ã–ª–∞ –≤—ã–±—Ä–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è¬†_a;_¬†
- _c_¬†‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±—É—Å—Ç–∏–Ω–≥–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ß–µ–º –æ–Ω –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ. (–í–æ–æ–±—â–µ —ç—Ç–æ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫ —Å—Ç–∞—Ç–∏—á–Ω—ã–º, —Ç–∞–∫ –∏ –¥–∏–Ω–∞–º–∏—á–Ω—ã–º. –¢–∞–∫ –∫–∞–∫ –Ω–∞–≥—Ä–∞–¥–∞ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º, –ª—É—á—à–µ —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –∑–∞–≤–∏—Å–∏–º—ã–º –æ—Ç –µ—ë –∑–Ω–∞—á–µ–Ω–∏—è.)

[**Thompson sampling**](https://www.google.com/url?q=https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf&sa=D&source=docs&ust=1685370309094896&usg=AOvVaw2iEcch3-Pf_IK76uvDczhS)¬†‚Äî —Å–∞–º—ã–π —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º MAB. –û–Ω –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ, –ø–æ—ç—Ç–æ–º—É —Å –Ω–∏–º –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω–æ —Å–≤—è–∑–∞–Ω–æ –¥–≤–∞ —Ç–µ—Ä–º–∏–Ω–∞:
- –ê–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –≤—ã—Ä–∞–∂–∞–µ—Ç –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è –¥–æ —É—á–µ—Ç–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
- –ê–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–æ –ø–æ—Å–ª–µ —É—á—ë—Ç–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–£ –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –±–∞–Ω–¥–∏—Ç–∞ –µ—Å—Ç—å –∞–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–≥–æ –Ω–∞–≥—Ä–∞–¥—ã, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ –º–µ—Ä–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω—ã–º. –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¢–æ–º–ø—Å–æ–Ω–∞ –±–µ—Ä–µ—Ç —Ä–∞–Ω–¥–æ–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —ç—Ç–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏—Ö –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º.

–î–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é Thompson sampling¬†–¥–ª—è¬†[–±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏](https://www.google.com/url?q=https://gdmarmerola.github.io/ts-for-bernoulli-bandit/&sa=D&source=docs&ust=1685370289544712&usg=AOvVaw0XS81AWTYsuz9aZnY5PTka). –í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑—å–º—ë–º –±–µ—Ç–∞-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ Œ± –∏ Œ≤: ![[Pasted image 20240531150603.png]]
**–≥–¥–µ Œ±_k –∏ Œ≤_k —è–≤–ª—è—é—Ç—Å—è –ø–æ —Å–≤–æ–µ–π —Å—É—Ç–∏ –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ–π —Å—É–º–º–æ–π –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–¥–∞—á–Ω—ã—Ö –∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∏—Å—Ö–æ–¥–æ–≤:**

–í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ theta, –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ –∏–∑ –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –Ω–∞—à–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.

–°–ª–µ–¥—É–µ—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –≤—Å–µ —ç—Ç–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Å–≤–æ–µ–º—É —É—Å–º–æ—Ç—Ä–µ–Ω–∏—é. –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ —Å–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å UCB –∏ Œµ-greedy –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –≤ –∞–ª–≥–æ—Ä–∏—Ç–º UCB, –ø—Ä–∏—á—ë–º –º–æ–∂–Ω–æ —ç—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–∞–∫ –µ–¥–∏–Ω–æ—Ä–∞–∑–æ–≤–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ, –∞ –∫–∞–∫ –ø–µ—Ä–∏–æ–¥, –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–¥–æ–º–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç—Ä–∞—Ñ–∏–∫, –∞ –ø–æ—Å–ª–µ —Å–Ω–æ–≤–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫ —Å–≤–æ–µ–º—É –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–º—É —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.
## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞ CMAB
1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∞–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: Prior(mu, std), –≥–¥–µ mu = 0, std = 1 (–∏–ª–∏ –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–æ—Å—á–∏—Ç–∞–µ—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–º–∏).¬†
    
2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¢–æ–º–ø—Å–æ–Ω–∞:

![BestAction(X_t, Prior, action)](https://habrastorage.org/getpro/habr/upload_files/edf/6e4/d75/edf6e4d752d10e49d7e170771cfbad6c.svg)

3. –í–∞—Ä–∏–∞–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –º–æ–¥–µ–ª–∏ —Ä–∞–Ω–¥–æ–º–Ω–æ —Å—ç–º–ø–ª–∏—Ä—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è¬†_Œ≤k_¬†–∏–∑ –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ —É–º–Ω–æ–∂–∞—é—Ç—Å—è –Ω–∞¬†_Xk_. –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–µ–¥–∏–∫—Ç–∞ –¥–∞–ª–µ–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ ‚Äî –∏ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.¬†    
4. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–≤—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –±–∞–Ω–¥–∏—Ç–∞ –∏ —Å–æ–±—Ä–∞—Ç—å –ø–µ—Ä–≤—ã–π –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö (–≤ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –≤—ã–±–æ—Ä –∏–∑ –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–¥–µ–Ω—Ç–∏—á–µ–Ω —Ä–∞–Ω–¥–æ–º–Ω–æ–º—É —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—é):¬†
![arm_t = BestAction(X_t, Prior, actions)](https://habrastorage.org/getpro/habr/upload_files/986/085/1a2/9860851a24f4073caa259421584fe56e.svg)
5. –ù–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞ –æ–±—É—á–∏—Ç—å –±–∞–π–µ—Å–æ–≤—Å–∫—É—é –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (—Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è):¬†¬†
![Prior_{new} = Posterior(mu, std)](https://habrastorage.org/getpro/habr/upload_files/013/560/e59/013560e59631c79b2b01dbb22fa86d45.svg)
6. –ò—Å–ø–æ–ª—å–∑—É—è –Ω–æ–≤–æ–µ –∞–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥–∏–∫—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞:
![arm_t = BestAction(Xt, Prior_{new}, actions)](https://habrastorage.org/getpro/habr/upload_files/b2e/efe/578/b2eefe57894e51eaeb8c651d9668b60e.svg)
7. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø—É–Ω–∫—Ç—ã 5 –∏ 6 –¥–ª—è –Ω–æ–≤—ã—Ö –±–∞—Ç—á–µ–π –¥–∞–Ω–Ω—ã—Ö n —Ä–∞–∑.

–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –±–∞–Ω–¥–∏—Ç linear TS –≥–æ—Ç–æ–≤! –û–¥–Ω–∞–∫–æ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω –ª–∏–Ω–µ–π–Ω—ã–π, —Ç–æ –µ—Å—Ç—å –±—É–¥–µ—Ç –¥–æ–≤–æ–ª—å–Ω–æ –ø–ª–æ—Ö–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ —Å–≤—è–∑–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –ø–æ–¥–∞–≤–ª—è—é—â–µ–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ. –†–µ—à–µ–Ω–∏–µ –¥–∞–Ω–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã –æ–ø–∏—Å–∞–ª–∏ –≤ —Å—Ç–∞—Ç—å–µ¬†[Deep Bayesian Bandits Showdown](https://www.google.com/url?q=https://research.google/pubs/pub46647/&sa=D&source=docs&ust=1685369012077265&usg=AOvVaw1xQGLPhuGvos4SkrtWoJfJ).

–î–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Ç–∞—Ä–≥–µ—Ç–æ–º –∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º neural linear TS, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π: –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∏ –ª–∏–Ω–µ–π–Ω–æ–π –±–∞–π–µ—Å–æ–≤—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –Ω–∞–ø—Ä—è–º—É—é –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –Ω–∞—à–∏ —Ñ–∏—á–∏ –≤ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é, –∫–∞–∫ –º—ã —ç—Ç–æ –¥–µ–ª–∞–ª–∏ –≤ —Å–ª—É—á–∞–µ —Å –ª–∏–Ω–µ–π–Ω—ã–º –±–∞–Ω–¥–∏—Ç–æ–º, –º—ã —Å–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏–º –Ω–∞ —ç—Ç–∏—Ö —Ñ–∏—á–∞—Ö –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –∏ –ø–æ—Ç–æ–º –≤–æ–∑—å–º—ë–º –∞—É—Ç–ø—É—Ç—ã –∏–∑ –µ—ë –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è¬† –≤ –∫–∞—á–µ—Å—Ç–≤–µ –Ω–æ–≤—ã—Ö —Ñ–∏—á, –∫–æ—Ç–æ—Ä—ã–µ –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –≠—Ç–∏ –Ω–æ–≤—ã–µ —Ñ–∏—á–∏, –ø–æ —Å—É—Ç–∏, —è–≤–ª—è—é—Ç—Å—è —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–µ–π –Ω–∞—à–∏—Ö –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–≤–∞–Ω—ã –æ–±–ª–µ–≥—á–∏—Ç—å –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π. –î–∞–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Å—Ö–µ–º—ã –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ –¥–∞–ª–µ–µ.
![[Pasted image 20240531151555.png]]


## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è CMAB

–¢–∞–∫ –∫–∞–∫ –º—ã –Ω–µ –º–æ–∂–µ–º –∑–Ω–∞—Ç—å, –∫–∞–∫–æ–µ –∞–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É Œ≤-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, –≤–æ–∑—å–º—ë–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ —Å—Ä–µ–¥–Ω–∏–º 0 –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º 1.¬†

–†–µ–∞–ª–∏–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏. –í –Ω–µ—ë –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á –º–æ–¥–µ–ª–∏:

```
def get_priors(arms, n_features):    
	posteriors = {}    
	for arm in arms:
		m = np.zeros(n_features)
		s = np.ones(n_features)
		posteriors[arm] = [m, s]
	return posteriors
```

–†–µ–∞–ª–∏–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¢–æ–º–ø—Å–æ–Ω–∞ (—Ñ—É–Ω–∫—Ü–∏—é BestAction –∏–∑ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏).
Œ± ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –≤–ª–∏—è–µ—Ç –Ω–∞ exploration / exploitation tradeoff. –ß–µ–º –º–µ–Ω—å—à–µ Œ±, —Ç–µ–º –º–µ–Ω—å—à–µ –¥–∏—Å–ø–µ—Ä—Å–∏—è —É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Œ≤ –∏ —Ç–µ–º –±–æ–ª—å—à–µ exploitation.

```
def select_arm_thompson(posteriors, context, arms, alpha = 1):  
	samples = {}
	context = np.insert(context, 0, 1)
	for arm in arms:
		m = posteriors[arm][0][:-1]
		s = posteriors[arm][1][:-1]* alpha
		w = np.random.normal(m, s)
		sample_prediction = np.dot(w, context)
		samples[arm] = sample_prediction
	max_value = max(samples.values());
	max_keys = [key for key, value in samples.items() if value == max_value]  
	return np.random.choice(max_keys)
```

–ü–æ—Å–ª–µ–¥–Ω–µ–µ, —á—Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ, ‚Äî —ç—Ç–æ —Å–∞–º–∞ –º–æ–¥–µ–ª—å. –í PyMC –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–π API¬†[](https://bambinos.github.io/bambi/main/index.html)[Bambi](https://bambinos.github.io/bambi/)¬†(BAyesian Model-Building Interface), —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –Ω—É–∂–Ω—É—é –Ω–∞–º –º–æ–¥–µ–ª—å –∏ –∑–∞–¥–∞—Ç—å –∞–ø—Ä–∏–æ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

(–í –∫–∞—á–µ—Å—Ç–≤–µ —Å—Ä–µ–¥—ã —Å–∏–º—É–ª—è—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º¬†[toy problem](https://www.google.com/url?q=https://github.com/LaunchpadAI/space-bandits/blob/master/toy_problem.ipynb&sa=D&source=docs&ust=1685369501292834&usg=AOvVaw0HFgzJpgA8Bu--ILIAyGYV)¬†–∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏¬†[Space Bandits (SB)](https://www.google.com/url?q=https://github.com/LaunchpadAI/space-bandits&sa=D&source=docs&ust=1685369517639214&usg=AOvVaw02hEdc2rm27HYrFfqsKCgL).)

## –í—ã–∫–∞—Ç –≤ –ø—Ä–æ–¥

1. –ü—Ä–æ–≤–µ—Å—Ç–∏ —Å–∏–º—É–ª—è—Ü–∏—é, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞–ª–∏ –º—ã –≤ toy problem, –Ω–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –° MAB —ç—Ç–æ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º ‚Äî –ø—Ä–æ—Ü–µ—Å—Å –ø–æ—Ö–æ–∂ –Ω–∞ —Å–∏–º—É–ª—è—Ü–∏—é A/B-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —Å CMAB –ø—Ä–∏–¥—ë—Ç—Å—è –Ω–µ–º–Ω–æ–≥–æ –Ω–∞–ø—Ä—è—á—å—Å—è. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–æ–π –∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –ø–æ–≤–µ–¥–µ–Ω–∏—è. –¢–æ–≥–¥–∞ –≤—ã —Å–º–æ–∂–µ—Ç–µ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å, –∫–∞–∫ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å CMAB –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
2. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å A/B-—Ç–µ—Å—Ç –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç—ã –±–∞–Ω–¥–∏—Ç–∞. –ë–µ–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –Ω–µ —Å—Ç–æ–∏—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å –±–∞–Ω–¥–∏—Ç–∞, —Ç–∞–∫ –∫–∞–∫ –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≤—ã –ø—Ä–æ—Å—Ç–æ –ª–∏—à–∏—Ç–µ—Å—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞.

# AirLLM

## Layer-wise inference

During inference, layers are executed sequentially. The output of the previous layer is the input to the next. Only one layer executes at a time.
Therefore, it is completely unnecessary to keep all layers in GPU memory.¬†**We can load whichever layer is needed from disk when executing that layer, do all the calculations, and then completely free the memory after.**
his way, the GPU memory required per layer is only about the parameter size of one transformer layer, 1/80 of the full model, around 1.6GB.

In addition, some output caches are also stored in GPU memory, the largest being the KV cache to avoid repeated computations.

A simple calculation, for the 70B model this KV cache size is about:

2 * input_length * num_layers * num_heads * vector_dim * 4

With input length 100, this cache = 2 * 100 * 80 * 8 * 128 * 4 = 30MB GPU memory.

**According to huggingface monitoring, the entire inference process uses less than 4GB GPU memory!**
## Single layer optimization Flash-attention

**Scaling the transformer architecture is heavily bottlenecked by the self-attention mechanism, which has quadratic time and memory complexity**. Recent developments in accelerator hardware mainly focus on enhancing compute capacities and not memory and transferring data between hardware. This results in attention operation having a memory bottleneck.¬†

**Flash Attention**¬†is an attention algorithm used to reduce this problem and scale transformer-based models more efficiently, enabling faster training and inference.

Standard attention mechanism uses High Bandwidth Memory (HBM) to store, read and write keys, queries and values. 

**HBM is large in memory, but slow in processing, meanwhile SRAM is smaller in memory, but faster in operations**. In the standard attention implementation, the cost of loading and writing keys, queries, and values from HBM is high. 
**It loads keys, queries, and values from HBM to GPU on-chip SRAM, performs a single step of the attention mechanism, writes it back to HBM, and repeats this for every single attention step. Instead, Flash Attention loads keys, queries, and values once, fuses the operations of the attention mechanism, and writes them back.**


![[Pasted image 20240613133141.png]]
![[Pasted image 20240614091359.png]]

### Key takeaways
The takeaway is that FlashAttention is:

- **Fast**¬†‚Äî excerpt from the paper: ‚ÄúWe train BERT-large (seq. length 512) 15% faster than the training speed record in MLPerf 1.1, GPT2 (seq. length 1K) 3x faster than baseline implementations from HuggingFace and Megatron-LM, and long-range arena (seq. length 1K-4K) 2.4x faster than baselines.‚Äù
- **Memory-efficient**¬†‚Äî compared to vanilla attention, which is quadratic in sequence length,¬†_O(N¬≤)_, this method is sub-quadratic/linear in N (_O(N)_). We‚Äôll see later why & how.
- **Exact**¬†‚Äî meaning it‚Äôs not an approximation of the attention mechanism (like e.g. sparse, or low-rank matrix approximation methods) ‚Äî its outputs are the same as in the ‚Äúvanilla‚Äù attention mechanism.
- **IO aware**

### Explanation [Background]

Let‚Äôs expand on this IO awareness part a bit more. ‚ÄúIO‚Äù is the reason more FLOPS doesn‚Äôt necessarily translate into longer wall-clock time.

Over the years GPUs have been adding compute capacity (FLOPS) at a faster pace than increasing the memory throughput (TB/s).

**It doesn‚Äôt matter if you can compute at exaFLOPS speeds if there is no data to be processed.**¬†These 2 need to be closely aligned, and since the hardware lost that balance we have to make our software compensate for it.

Depending on this ratio between computation and memory accesses, operations can be classified as either:

- **compute-bound**¬†(example: matrix multiplication)
- OR¬†**memory-bound**¬†(examples: elementwise ops (activation, dropout, masking), reduction ops (softmax, layer norm, sum, etc.)‚Ä¶)

*Note on the terminology: this ratio is commonly measured by the¬†**arithmetic intensity**, which is the number of arithmetic operations per byte of memory access.*

It turns out¬†**attention is**¬†(on current AI accelerators)¬†**memory-bound**.

Why?

Because it ‚Äúmostly consists of elementwise ops‚Äù or more accurately the arithmetic density of attention is not very high.
![[Pasted image 20240614091837.png]]A100 GPU has¬†**40‚Äì80GB**¬†of high bandwidth memory (HBM, the thing that gives you lovely CUDA OOMs) with a bandwidth of¬†**1.5‚Äì2.0 TB/s**¬†and¬†**192KB**¬†of on-chip SRAM per each of 108 streaming multiprocessors with bandwidth estimated around¬†**19TB/s.**

Standard attention schema is the following: 
![[Pasted image 20240614092110.png]]The lowest hanging fruit is to¬†**remove redundant HBM reads/writes**.
Why write¬†**_S_**¬†back to HBM only to (re)load it again in order to compute the softmax? Let‚Äôs keep it in SRAM instead, perform all of the intermediate steps, and only then write the final result back to HBM

This is what compilers folks refer to as¬†**‚Äúkernel fusion‚Äù**, one of the most important low-level optimizations in deep learning:
![[Pasted image 20240614094901.png]]==A==¬†==**_kernel_**==¬†==is basically a fancy way of saying ‚Äúa GPU operation‚Äù.
**_Fusion_**¬†means you‚Äôre fusing/combining multiple ops together

So, you are loading from the HBM only¬†**once,**¬†you execute the fused op, and only then write the results back. By doing this you reduce the communication overhead.

One final piece of terminology you‚Äôll find floating around is¬†**‚Äúmaterialization‚Äù**. 
It refers to the fact that in the above standard attention implementation, we‚Äôve¬†**allocated**¬†full¬†**NxN**¬†matrices (**_S_**,¬†**_P_**). We‚Äôll soon see that that‚Äôs the bottleneck flash attention directly tackles reducing the memory complexity from¬†_O(N¬≤)_¬†to¬†_O(N)._


Flash attention basically boils down to 2 main ideas:

1. **Tiling**¬†(used during both forward & backward passes) ‚Äî basically chunking the NxN softmax/scores matrix into blocks.

2.¬†**Recomputation**¬†(used in the backward pass only ‚Äî if you‚Äôre familiar with activation/gradient checkpointing, this will be trivial to understand)

![[Pasted image 20240614095324.png]]

### FlashAttention [Main algorithm]

The main hurdle in getting the tiling approach to work is softmax. 
**In particular, the fact that softmax couples all of the score columns together. 
Here is how we compute the¬†_i-th_¬†output of a softmax.**:
![[Pasted image 20240614095608.png]]
The denominator is the issue.

**To compute how much a particular¬†_i-th_¬†token from the input sequence pays attention to other tokens in the sequence you‚Äôd need to have all of those scores readily available (denoted here by¬†_z_j_) in SRAM. But let me remind you: SRAM is severely limited in its capacity. You can‚Äôt just load the whole thing. N (sequence length) can be 1000 or¬†even 100.000¬†tokens. So¬†_N¬≤_¬†explodes fairly quickly.**

```
So here‚Äôs the trick, we can actually chop the softmax computation down into smaller blocks and still end up with precisely the same result.
```
![[Pasted image 20240614095823.png]]`These numbers are, at least for now, incorrect.But bear with me, through iterations, we‚Äôll ‚Äúconverge‚Äù to a correct result`

> Note:¬†**you can ignore the m(x)**¬†part, at least for now while we‚Äôre still in Plato‚Äôs world of ideas. Its purpose is solely to avoid numerical instabilities. On some hypothetical hardware from the future that‚Äôs more precise (e.g. we represent our data using more bits) this would not be needed.¬†**m(x)**¬†does not change the final result in any way.

We can combine those per-block partial softmax numbers in a smart way such that the final result is actually correct. Here is the main idea:
![[Pasted image 20240614100444.png]]So basically, in order to compute the softmax for the scores belonging to the first 2 blocks (of size¬†_B_), you have to keep track of 2 statistics for each of the blocks:¬†**_m(x)_**¬†(maximum score) and¬†**_l(x)_**¬†(sum of exp scores).

And then you can seamlessly fuse them together using the normalizing coefficients.

This logic continues recursively all the way up to the last,¬†_(N/B)-th,_¬†block, at which point you have the N-dimensional correct softmax output!

> Note: the algo below assumes we have a batch of size 1 (i.e. single sequence) and a single attention head, we‚Äôll easily scale it up later (by simply parallelizing across GPU‚Äôs streaming multiprocessors ‚Äî more on that later). Also we ignore dropout & masking for the time being, trivial to add it later.


![[Pasted image 20240614101221.png]]
#### Steps 
S**tep 0:**¬†HBM‚Äôs capacity is measured in GBs (e.g. RTX 3090 has 24 GBs of VRAM/HBM, A100 has 40‚Äì80 GB, etc.) so allocating¬†**_Q_**,¬†**_K_**, and¬†**_V_**¬†is not an issue.

**Step 1:**¬†Let‚Äôs compute the row/column block sizes. Why¬†_ceil(M/4d)_? Because query, key, and value vectors are d-dimensional, and, we also need to combine them into the output d-dimensional vector. So this size basically allows us to max out SRAM capacity with¬†_q_,¬†_k_,¬†_v_, and¬†_o_¬†vectors.

Toy example: assume M = 1000, d = 5. In this example, the block size is (1000/4*5) = 50. So in this example, we would load blocks of 50¬†_q, k, v, o_¬†vectors at a time, to make sure we‚Äôre reducing the number of reads/writes between HBM/SRAM.

**Step 2:**

We initialize the output matrix¬†**_O_**¬†with all 0s. It‚Äôll act as an accumulator hence that init value. Similarly for¬†**_l_**¬†(remember: its purpose is to hold the cumulative denominator for the softmax - the sum of exp scores).¬†**_m_**¬†(that holds row-wise maximum scores)¬†is initialized with¬†_-inf_¬†because we‚Äôll be doing a max operator over it so whatever the first block‚Äôs max is ‚Äî it‚Äôll certainly be larger than¬†_-inf ‚Äî_¬†hence this is the natural init value.

**Step 3:
We split the¬†**_Q, K,_**¬†and¬†**_V_**¬†into blocks using the block sizes from Step 1. 

**Step 4**:
Similarly split¬†**_O, l, m_**¬†into blocks (same block size as¬†**_Q_**)

Step 5:
Let‚Äôs start looping across the columns i.e. across key/value vectors (**outer loop**¬†in the diagram above).

Step 6:
Let‚Äôs load the¬†**_K_j_**¬†and¬†**_V_j_**¬†blocks from HBM to SRAM. Remember because of the way we constructed the block sizes we still have 50% of the SRAM unoccupied at this point in time (dedicated to¬†**Q**¬†and¬†**O**)

Step 7: 
Start the¬†**inner loop**¬†across the rows i.e. across query vectors (again, see the diagram).

Step 8:
Load¬†**_Q_i_**¬†(_B_r x d_) and¬†**_O_i (_**_B_r x d_**_)_**¬†blocks, as well as¬†**_l_i_**¬†(_B_r_) &¬†**_m_i (_**_B_r_**_)_**¬†into SRAM.

How do¬†**_l_i_**¬†&¬†**_m_i_**¬†fit into the SRAM (including all of the intermediate variables) when we computed block size in such a way that we only have enough space for¬†**_K_j_**,¬†**_V_j_**,¬†**_Q_i_**¬†&¬†**_O_i_**? I think the answer is: registers (see¬†[this CUDA video series](https://www.youtube.com/watch?v=4APkMJdiudU&list=PLC6u37oFvF40BAm7gwVP7uDdzmW83yHPe)¬†to get some intuition on GPU memory hierarchy). But I might be wrong, 

Step 9:
Compute the dot product between¬†**_Q_i_**¬†(_B_r x d_) and¬†**_K_j_**¬†transposed (_d x B_c_) to get the scores (_B_r x B_c_). As you can see we don‚Äôt have the whole¬†_NxN_¬†**_S_**¬†(scores) matrix ‚Äúmaterialized‚Äù. Only a fraction of it (**_S_i_j_**)!

Step 10: 
Compute¬†**_m~_i_j_**,¬†**_l~_i_j_**, and¬†**_P~_i_j_**¬†using the scores computed in the previous step. It‚Äôs trivial.

**_m~_i_j_**¬†is computed row-wise, find the max element for each of the above rows.

We get¬†**_P~_i_j_**¬†by applying elementwise ops:

1. Normalization ‚Äî take the row max and subtract it from row scores
2. Exp

**_l~_i_j_**¬†is simply a row-wise sum of the matrix P.

Step 11:
Compute¬†**_m_new_i_**¬†and¬†**_l_new_i_**.
**_m_i_**¬†contains row-wise maximums for all of the blocks that came before.¬†**_m~_i_j_**¬†contains the row-wise maximums for the current block . To get the¬†**_m_new_i_**¬†we just have to apply a max between¬†**_m~_i_j_**¬†&¬†**_m_i_**. Similarly for¬†**_l_new_i_**¬†(it additionally requires multiplying by coefficients as we saw previously in¬†_formula 2_).


Step 12 (Most important step):
![[Pasted image 20240614105637.png]]
This is the hardest part of the algorithm but still not that complicated, esp. once you internalize the¬†_formulas 1 & 2_¬†for partial softmax computation.

Let‚Äôs break down the¬†**_diag(l)_**¬†part first.

It basically just allows us to do row-wise scalar multiplication in a matrix form. If you have a list of scalars¬†**_s_**¬†(_N_)¬†and a matrix¬†**_A (_**_NxN_**_)_**, if you do¬†**_diag(s)_*****_A_**¬†you‚Äôre basically doing elementwise multiplication of rows of¬†**_A_**¬†with those scalars


So what the 1st term of step 12 does (underlined in green) is it updates the current softmax estimate for the blocks before the current block in the same row of blocks. In case j=1 (that is the first block in this row) the 1st term will be 0 and we‚Äôll just end up with the 2nd term.
The multiplication of the 1st term by¬†**_diag(l_i)_**¬†is there to cancel the division by that same constant from the previous iteration (this constant is hidden inside of¬†**_O_i_**).

The 2nd term of the expression (underlined in yellow) doesn‚Äôt require this canceling of terms because as you can see we‚Äôre directly multiplying the¬†**_P~_i_j_**¬†matrix with the block of¬†**_V_**¬†vectors (**_V_j_**).

The¬†**_e^x_**¬†terms are there to modify the matrix¬†**_P~_i_j_**¬†&¬†**_O_i_**¬†by canceling out the¬†**_m_**¬†from the previous iteration and instead updating it with the latest estimate (**_m_new_i_**) that contains the row-wise max so far.

Step 13: 
Write the newest cumulative statistics (**_l_i_**¬†&¬†**_m_i_**) back to HBM. Notice these are of dimension¬†_B_r_.

Step 14.15,16:
Once the nested for loop is over,¬†**_O_**¬†(Nxd) will contain the final result: attention-weighted value vectors for each of the input tokens

This algorithm can easily be extended to ‚Äúblock-sparse FlashAttention‚Äù, a sparse attention algorithm that is 2‚Äì4 faster than even FlashAttention, scaling up to a sequence length of 64k! The idea is we use a block form mask matrix and we simply skip certain loads/stores from the above nested for loop and by doing so we can save proportionally to the sparsity coefficient.


### Scaling

Let‚Äôs start with the low-hanging fruit. Extending the implementation we saw to support¬†_batch_size_¬†> 1 and the¬†_num_heads_¬†> 1 is actually not that hard.

So far the algorithm we saw is basically handled by a single¬†**_thread block_**¬†(CUDA programming lingo). This thread block is executed on a single¬†**_streaming multiprocessor_**¬†(SM) (e.g. there are 108 of these on A100). To parallelize our computation we just run¬†_batch_size_¬†*¬†_num_heads_¬†threadblocks in parallel on different SMs. The closer that number is to the number of available SMs on the system the higher the utilization will be (ideally a multiple as each SM can run multiple thread blocks).

What happens when that number is bigger than the number of available SMs? I‚Äôm not sure but I assume there is a queue that keeps track of the waiting kernels (update:¬†[apparently](https://www.youtube.com/watch?v=xwbD6fL5qC8&t=760s&ab_channel=TomNurkkala)¬†the CUDA runtime takes care of that and it is using some sort of queues to implement that logic).

The backward pass relies on the same set of concepts +¬†**_recomputation_**.

To demonstrate the concept of recomputation I‚Äôll use the example of ‚Äú_activation/gradient checkpointing_‚Äù method.

We know that we need to have the activations computed during the forward pass readily available during the backward pass in order to compute the gradients w.r.t. our loss function.

The trick here is to not store them during the fwd pass (as they have a huge memory footprint), but instead, recompute them de novo during the backward pass. There is a built-in¬†**tradeoff**¬†here: we‚Äôre slowing down the backward pass in order to reduce the memory footprint.

> Note: This tradeoff is a spectrum, e.g. you can store the activations every¬†_n_¬†layers, and then when computing the activations for the i-th layer you don‚Äôt have to start from the input but instead from the closest stored activations.

The same concept of recomputation is re-used here ‚Äî but with a twist! Luckily for the flash attention, we don‚Äôt have to sacrifice neither runtime nor memory!

By storing the output¬†**_O_**¬†(_Nxd_) and the softmax normalization statistics (_N_) we can recompute the attention matrices¬†**_S_**¬†(_NxN_) and¬†**_P_**¬†(_NxN_) in the backward pass directly from blocks of¬†**_Q_**,¬†**_K_**, and¬†**_V_**¬†(_Nxd_) in SRAM! Thus keeping the memory at¬†_O(N)_.




## Model File Sharding

The original model file is usually sharded into multiple chunks, typically 10GB each.
Our execution processes layer by layer. Each layer is only 1.6GB. If we load based on the original 10GB shards, every layer execution will require reloading the entire 10GB file but only using 1.6GB

This process wastes a lot of memory for loading and disk reading. Disk reading speed is actually the slowest bottleneck in the whole inference process, so we want to minimize it as much as possible.
Therefore, we first¬†**pre-process the original HuggingFace model file and shard it by layers**.

**Safetensor ensures the storage format and in-memory format match closely, and uses memory mapping for loading to maximize speed.**

## Meta device

Meta device is a¬†**virtual device**¬†designed specifically for running ultra large models.¬†**When you load a model via meta device, the model data is not actually read in, only the code is loaded. Memory usage is 0.**

You can dynamically transfer parts of the model from meta device to a real device like CPU or GPU during execution. Only then is it actually loaded into memory.

Using init_empty_weights() allows model loading via meta device.

```
from accelerate import init_empty_weights
with init_empty_weights():
    my_model = ModelClass(...)
```

## AirLLM inference

```
from airllm import AirLLMLlama2

MAX_LENGTH = 128
# could use hugging face model repo id:
model = AirLLMLlama2("garage-bAInd/Platypus2-70B-instruct")

# or use model's local path...
#model = AirLLMLlama2("/home/ubuntu/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f")

input_text = [
        'What is the capital of United States?',
    ]

input_tokens = model.tokenizer(input_text,
    return_tensors="pt", 
    return_attention_mask=False, 
    truncation=True, 
    max_length=MAX_LENGTH, 
    padding=True)
           
generation_output = model.generate(
    input_tokens['input_ids'].cuda(), 
    max_new_tokens=20,
    use_cache=True,
    return_dict_in_generate=True)

output = model.tokenizer.decode(generation_output.sequences[0])

print(output)

```